<!DOCTYPE html><html lang="zh-Hans"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"><meta name="description" content="coursera 吴恩达深度学习 Specialization 笔记（course 4 week 4）—— 人脸识别"><meta name="keywords" content="吴恩达深度学习笔记,AI,cnn,人脸识别"><meta name="author" content="陈艺琛,undefined"><meta name="copyright" content="陈艺琛"><title>coursera 吴恩达深度学习 Specialization 笔记（course 4 week 4）—— 人脸识别 | 艺琛的 Livehouse</title><link rel="shortcut icon" href="/img/logo1.png"><link rel="stylesheet" href="/css/index.css?version=1.5.6"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/font-awesome@4.7.0/css/font-awesome.min.css?version=1.5.6"><link rel="dns-prefetch" href="https://cdn.staticfile.org"><link rel="dns-prefetch" href="https://cdn.bootcss.com"><link rel="dns-prefetch" href="https://creativecommons.org"><link rel="dns-prefetch" href="https://hm.baidu.com"><script>var _hmt = _hmt || [];
(function() {
  var hm = document.createElement("script");
  hm.src = "https://hm.baidu.com/hm.js?20c8efd323cd63b9f6bf846113eb6f60";
  var s = document.getElementsByTagName("script")[0]; 
  s.parentNode.insertBefore(hm, s);
})();</script><script>var GLOBAL_CONFIG = { 
  root: '/',
  algolia: undefined,
  localSearch: {"path":"search.xml","languages":{"hits_empty":"找不到您查询的内容:${query}"}},
  copy: {
    success: '复制成功',
    error: '复制错误',
    noSupport: '浏览器不支持'
  }
} </script></head><body><canvas class="fireworks"></canvas><i class="fa fa-arrow-right" id="toggle-sidebar" aria-hidden="true"></i><div id="sidebar"><div class="toggle-sidebar-info text-center"><span data-toggle="切换文章详情">切换站点概览</span><hr></div><div class="sidebar-toc"><div class="sidebar-toc__title">目录</div><div class="sidebar-toc__progress"><span class="progress-notice">你已经读了</span><span class="progress-num">0</span><span class="progress-percentage">%</span><div class="sidebar-toc__progress-bar"></div></div><div class="sidebar-toc__content"><ol class="toc"><li class="toc-item toc-level-2"><a class="toc-link" href="#人脸识别"><span class="toc-number">1.</span> <span class="toc-text">人脸识别</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#什么是人脸识别或人脸校验"><span class="toc-number">1.1.</span> <span class="toc-text">什么是人脸识别或人脸校验</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#单样本学习-one-shot-learning"><span class="toc-number">1.2.</span> <span class="toc-text">单样本学习 one-shot learning</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#孪生网络-Siamese-network"><span class="toc-number">1.3.</span> <span class="toc-text">孪生网络 Siamese network</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#三元损失函数-Triple-Loss"><span class="toc-number">1.4.</span> <span class="toc-text">三元损失函数 Triple Loss</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#引例"><span class="toc-number">1.4.1.</span> <span class="toc-text">引例</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#三元损失函数定义"><span class="toc-number">1.4.2.</span> <span class="toc-text">三元损失函数定义</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#如何选择三元组-A-P-N"><span class="toc-number">1.4.3.</span> <span class="toc-text">如何选择三元组 A, P, N</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#人脸识别的二元分类方法"><span class="toc-number">1.5.</span> <span class="toc-text">人脸识别的二元分类方法</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#神经风格转化-Neural-style-transfer"><span class="toc-number">2.</span> <span class="toc-text">神经风格转化 Neural style transfer</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#什么是神经风格转化"><span class="toc-number">2.1.</span> <span class="toc-text">什么是神经风格转化</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#深度卷积网络的可视化"><span class="toc-number">2.2.</span> <span class="toc-text">深度卷积网络的可视化</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#代价函数"><span class="toc-number">2.3.</span> <span class="toc-text">代价函数</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#内容代价函数"><span class="toc-number">2.4.</span> <span class="toc-text">内容代价函数</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#风格代价函数"><span class="toc-number">2.5.</span> <span class="toc-text">风格代价函数</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#如何定义一张图片的“风格”"><span class="toc-number">2.5.1.</span> <span class="toc-text">如何定义一张图片的“风格”</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#关于图片风格的解释"><span class="toc-number">2.5.2.</span> <span class="toc-text">关于图片风格的解释</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#风格矩阵"><span class="toc-number">2.5.3.</span> <span class="toc-text">风格矩阵</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#风格代价函数-1"><span class="toc-number">2.5.4.</span> <span class="toc-text">风格代价函数</span></a></li></ol></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#1D-和-3D-卷积"><span class="toc-number">3.</span> <span class="toc-text">1D 和 3D 卷积</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#2D-到-1D-的推广"><span class="toc-number">3.1.</span> <span class="toc-text">2D 到 1D 的推广</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#2D-到-3D-的推广"><span class="toc-number">3.2.</span> <span class="toc-text">2D 到 3D 的推广</span></a></li></ol></li></ol></div></div><div class="author-info hide"><div class="author-info__avatar text-center"><img src="/img/avater.jpg"></div><div class="author-info__name text-center">陈艺琛</div><div class="author-info__description text-center">a student of HITsz————坚持滑板，热爱摇滚，偶尔弹吉他，喜欢阅读，抽空打游戏，在AI小白之路上踽踽独行。</div><div class="follow-button"><a href="https://web.okjike.com/user/9e0ec001-4bb6-4cab-af94-ea8b2f6067ef/post" target="_blank">在即刻上关注我</a></div><hr><div class="author-info-articles"><a class="author-info-articles__archives article-meta" href="/archives"><span class="pull-left">文章</span><span class="pull-right">33</span></a><a class="author-info-articles__tags article-meta" href="/tags"><span class="pull-left">标签</span><span class="pull-right">27</span></a><a class="author-info-articles__categories article-meta" href="/categories"><span class="pull-left">分类</span><span class="pull-right">3</span></a></div><hr><div class="author-info-links"><div class="author-info-links__title text-center">友链</div><a class="author-info-links__name text-center" href="https://www.liaoxuefeng.com" target="_blank">廖雪峰的博客</a><a class="author-info-links__name text-center" href="https://mooc.study.163.com/smartSpec/detail/1001319001.htm" target="_blank">网易机器学习公开课</a><a class="author-info-links__name text-center" href="https://developers.google.com/machine-learning/crash-course/?hl=zh-cn" target="_blank">谷歌机器学习速成</a><a class="author-info-links__name text-center" href="http://www.hitsz.edu.cn/index.html" target="_blank">哈工大深圳主页</a></div></div></div><div id="content-outer"><div id="top-container" style="background-image: url(https://raw.githubusercontent.com/yichenchan/blogimg/master/img/dl_topimg.png)"><div id="page-header"><span class="pull-left"> <a id="site-name" href="/">艺琛的 Livehouse</a></span><i class="fa fa-bars toggle-menu pull-right" aria-hidden="true"></i><span class="pull-right menus"><a class="site-page social-icon search"><i class="fa fa-search"></i><span> 搜索</span></a><a class="site-page" href="/">主页</a><a class="site-page" href="/categories/学习笔记">学习笔记</a><a class="site-page" href="/categories/读书观影笔记">读书观影笔记</a><a class="site-page" href="/categories/个人随想">个人随想</a><a class="site-page" href="/categories/爱好和生活">爱好和生活</a><a class="site-page" href="/gallery">相册</a><a class="site-page" href="/archives">所有博客</a><a class="site-page" href="/tags">特色标签</a><a class="site-page" href="/about">关于我</a></span></div><div id="post-info"><div id="post-title">coursera 吴恩达深度学习 Specialization 笔记（course 4 week 4）—— 人脸识别</div><div id="post-meta"><time class="post-meta__date"><i class="fa fa-calendar" aria-hidden="true"></i> 2018-11-01</time><span class="post-meta__separator">|</span><i class="fa fa-inbox post-meta__icon" aria-hidden="true"></i><a class="post-meta__categories" href="/categories/学习笔记/">学习笔记</a></div></div></div><div class="layout" id="content-inner"><article id="post"><div class="article-container" id="post-content"><p>这一周我们将学习到如何利用 CNN 进行图片风格转换和人脸识别。</p>
<h2 id="人脸识别"><a href="#人脸识别" class="headerlink" title="人脸识别"></a>人脸识别</h2><h3 id="什么是人脸识别或人脸校验"><a href="#什么是人脸识别或人脸校验" class="headerlink" title="什么是人脸识别或人脸校验"></a>什么是人脸识别或人脸校验</h3><ul>
<li>人脸校验<ul>
<li>输出图片，姓名或身份号</li>
<li>输出是否输入图片是对应的那个人</li>
<li>这是一个 1：1 问题</li>
</ul>
</li>
<li>人脸识别<ul>
<li>有 K 个人的数据库</li>
<li>输入图片</li>
<li>输出这个人的 ID 号，如果它是这 K 个人之一的话，如果不是，输出“未识别”</li>
<li>这是一个 1：K 问题</li>
</ul>
</li>
</ul>
<a id="more"></a>
<h3 id="单样本学习-one-shot-learning"><a href="#单样本学习-one-shot-learning" class="headerlink" title="单样本学习 one-shot learning"></a>单样本学习 one-shot learning</h3><p>单样本学习指的是用<strong>一张</strong>样本照片进行学习，然后再次识别出这个人。由于只有一个样本，所以如果直接输入到 CNN 进行训练，效果非常不好。</p>
<p>正确的做法是学习出一个“相似度”函数 <code>d(img1, img2)</code>，它等于两个图片的不同程度，如果 $d(img1, img2) \le \tau$，那么这两张图片就是一个人，如果反之，这不是一个人。</p>
<h3 id="孪生网络-Siamese-network"><a href="#孪生网络-Siamese-network" class="headerlink" title="孪生网络 Siamese network"></a>孪生网络 Siamese network</h3><p>[Taigman et. al., 2014. DeepFace closing the gap to human level performance] </p>
<p>假设我们有两张图片 $x^{(1)}, x^{(2)}$，我们将它们通过一个卷积网络，输出两个编码向量 $f(x^{(1)})$ 和 $f(x^{(2)})$，训练这个网络，使得我们确信这个编码是对这两张图片的良好表达，这个相似度函数就是两张照片的编码的差的范数。</p>
<script type="math/tex; mode=display">
d(x^{(1)},x^{(2)})=||f(x^{(1)})-f(x^{(2)})||^2_2</script><p>这个概念被称作孪生网络。</p>
<p><img src="https://raw.githubusercontent.com/yichenchan/blogimg/master/img/dl_4.4_1.png" alt=""></p>
<p>如何训练？</p>
<p><img src="https://raw.githubusercontent.com/yichenchan/blogimg/master/img/dl_4.4_2.png" alt=""></p>
<ul>
<li>神经网络的参数定义了图片的一个编码 $f(x^{(i)})$</li>
<li>学习参数使得：<ul>
<li>如果 $x^{(i)}$ 和 $x^{(j)}$ 是同一个人，那么 $||f(x^{(1)})-f(x^{(2)})||^2_2$ 就很小</li>
<li>如果 $x^{(i)}$ 和 $x^{(j)}$ 是不同的人，那么 $||f(x^{(1)})-f(x^{(2)})||^2_2$ 就很大</li>
</ul>
</li>
</ul>
<h3 id="三元损失函数-Triple-Loss"><a href="#三元损失函数-Triple-Loss" class="headerlink" title="三元损失函数 Triple Loss"></a>三元损失函数 Triple Loss</h3><h4 id="引例"><a href="#引例" class="headerlink" title="引例"></a>引例</h4><p>首先我们有一个“锚 Anchor”照片 A，如果另一张照片和这个锚照片是同一个人，着称之为“正例 Positive” P，反之称为“反例 Negative” N，如下图所示：</p>
<p><img src="https://raw.githubusercontent.com/yichenchan/blogimg/master/img/dl_4.4_3.png" alt=""></p>
<p>我们期望的是 A 和 P 的差距 d(A, P) 要小于 A 和 N 的差距 d(A, N)，即：</p>
<script type="math/tex; mode=display">
d(A, P) \le d(A,N) \\
||f(A)-f(P)||^2 \le ||f(A)-f(N)||^2\\
||f(A)-f(P)||^2 - ||f(A)-f(N)||^2 \le 0</script><p>但是为了防止神经网络把 f(A) 和 f(P) 和 f(N) 训练得特别接近，例如当它们都为 0 时，上式仍然满足，为了防止神经网络输出退化解，增大 d(A, P) 和 d(A, N) 之间的差距，我们增加一个超参数 margin $\alpha$，式子变成：</p>
<script type="math/tex; mode=display">
d(A, P) + \alpha \le d(A,N) \\
||f(A)-f(P)||^2 + \alpha  \le ||f(A)-f(N)||^2 \\
||f(A)-f(P)||^2 - ||f(A)-f(N)||^2 + \alpha \le 0</script><p>当 d(A, P) = 0.5 时，加上 $\alpha$ = 0.2，则 d(A, N) 至少为 0.7，使得 d(A, P) 远小于 d(A, N)。</p>
<h4 id="三元损失函数定义"><a href="#三元损失函数定义" class="headerlink" title="三元损失函数定义"></a>三元损失函数定义</h4><p>给定三个图片 A，P，N：</p>
<script type="math/tex; mode=display">
L(A,P,N)=max(||f(A)-f(P)||^2 - ||f(A)-f(N)||^2 + \alpha, \  0 )</script><p>总的代价函数为：</p>
<script type="math/tex; mode=display">
J = \sum\limits ^m_{i=1}L(A^{(i)},P^{(i)},N^{(i)})</script><p>我们必须保证每个人不止一张照片，假设训练集为 1000 个人的 10000 张照片，我们需要拿这 10000 张照片去生成上式的三元组。</p>
<h4 id="如何选择三元组-A-P-N"><a href="#如何选择三元组-A-P-N" class="headerlink" title="如何选择三元组 A, P, N"></a>如何选择三元组 A, P, N</h4><p>在训练时，如果你随意选择 A，P，N，那么 $d(A, P) + \alpha \le d(A,N)$ 这个式子会非常容易满足，因为如果随便挑的 d(A, P) 会有很大几率远小于 d(A, N)，这样导致神经网络无法从中学到东西。</p>
<p>我们需要做的是挑选那种<strong>很难训练</strong>的三元组，使得你挑的 A, P, N 会让 d(A,P) 很靠近 d(A,N)，这样使得算法在学习的时候要花更多的力气尝试让右边这一项增大，左边这项减小，也就是使得：</p>
<script type="math/tex; mode=display">
d(A, P)  \approx  d(A, N)</script><p><img src="https://raw.githubusercontent.com/yichenchan/blogimg/master/img/dl_4.4_4.png" alt=""></p>
<p>更多三元组选择方法见这篇论文。</p>
<h3 id="人脸识别的二元分类方法"><a href="#人脸识别的二元分类方法" class="headerlink" title="人脸识别的二元分类方法"></a>人脸识别的二元分类方法</h3><p>除了三元损失函数，我们还有其他的定义损失函数的方法。</p>
<p><img src="https://raw.githubusercontent.com/yichenchan/blogimg/master/img/dl_4.4_5.png" alt=""></p>
<script type="math/tex; mode=display">
\hat y = \sigma (\sum\limits ^{128} _{k=1}w_i|f(x^{(i)})_k-f(x^{(j)})_k|+b)</script><p>还有一种变种 $\chi ^2$ 相似度：</p>
<script type="math/tex; mode=display">
\hat y = \sigma (\sum\limits ^{128} _{k=1}w_i \frac{(f(x^{(i)})_k-f(x^{(j)})_k)^2}{f(x^{(i)})_k+f(x^{(j)})_k}  +b)</script><p>一个小技巧是我们不必每次都计算数据库中的图片的编码值，我们可以先进行预计算，在进行识别时直接跟这些预计算的编码值进行比较，然后预测结果 y.</p>
<p><img src="https://raw.githubusercontent.com/yichenchan/blogimg/master/img/dl_4.4_6.png" alt=""></p>
<h2 id="神经风格转化-Neural-style-transfer"><a href="#神经风格转化-Neural-style-transfer" class="headerlink" title="神经风格转化 Neural style transfer"></a>神经风格转化 Neural style transfer</h2><h3 id="什么是神经风格转化"><a href="#什么是神经风格转化" class="headerlink" title="什么是神经风格转化"></a>什么是神经风格转化</h3><p><img src="https://raw.githubusercontent.com/yichenchan/blogimg/master/img/dl_4.4_7.png" alt=""></p>
<h3 id="深度卷积网络的可视化"><a href="#深度卷积网络的可视化" class="headerlink" title="深度卷积网络的可视化"></a>深度卷积网络的可视化</h3><p>假设我们正在训练这样一个网络：</p>
<p><img src="https://raw.githubusercontent.com/yichenchan/blogimg/master/img/dl_4.4_8.png" alt=""></p>
<p>为了知道每一层到底在计算什么，并将其可视化，我们可以在这层挑出一个神经元，找到使得这个神经元激活值最大的九个图像小块。在更深的层，隐藏单元能看到更大一部分图像，即更大图像对这些层的输出有影响，我们将每一层可视化，如下图所示。</p>
<p><img src="https://raw.githubusercontent.com/yichenchan/blogimg/master/img/dl_4.4_9.png" alt=""></p>
<p>我们可以看到，第一层在检测一些边缘特征，随着层数的加深，检测的对象越来越复杂。</p>
<h3 id="代价函数"><a href="#代价函数" class="headerlink" title="代价函数"></a>代价函数</h3><p>[Gatys et al., 2015. A neural algorithm of artistic style. Images on slide generated by Justin Johnson] </p>
<p>问题的形式是：我们有一张“内容 content 图片” C，一张“风格 style 图片” S，得到一个“生成 generated 图像” G。我们需要一个代价函数 J(G) 来评价某个图像生成的质量有多好，用梯度下降使得 G 的损失最小，从而生成想要的图像。</p>
<p>代价函数分为两部分： 内容代价函数，表示生成图像和内容图像之间的相似程度，以及风格代价函数，表示生成图像和风格图像之间的相似程度，再加上两个系数表示风格代价和内容代价之间的比重。</p>
<script type="math/tex; mode=display">
J(G)= \alpha J_{content}(C,G)+\beta J_{style}(S,G)</script><p><strong>如何生成 G</strong>：</p>
<ul>
<li>将 G 随机初始化<ul>
<li>G : 100×100×3</li>
</ul>
</li>
<li>使用梯度下降最小化 J(G) <ul>
<li>$G:=G- \frac{\partial J(G)}{\partial G}$ 不同于更新权重，我们通过梯度下降更新 G 的像素值来最小化 J(G)</li>
</ul>
</li>
</ul>
<p><img src="https://raw.githubusercontent.com/yichenchan/blogimg/master/img/dl_4.4_10.png" alt=""></p>
<h3 id="内容代价函数"><a href="#内容代价函数" class="headerlink" title="内容代价函数"></a>内容代价函数</h3><script type="math/tex; mode=display">
J(G)= \alpha J_{content}(C,G)+\beta J_{style}(S,G)</script><ul>
<li>假设使用 $l$ 个隐藏层来计算内容代价函数</li>
<li>使用预训练的卷积网络，比如 VGG 网络</li>
<li>分别将内容图片 C 和生成图片 G 输入这个网络，假设 $a ^ { [ l ] ( C ) }$ 和 $a ^ { [ l ] ( G ) }$ 分别是第 $l$ 层的内容图像 C 和生成图片 G 的<strong>激活值</strong></li>
<li>如果 $a ^ { [ l ] ( C ) }$ 和 $a ^ { [ l ] ( G ) }$ 很接近，那么两张图片就有相似的内容，所以内容代价函数为：</li>
</ul>
<script type="math/tex; mode=display">
J_{content}(C,G) = \frac{1}{2}||a ^ { [ l ] ( C ) } - a ^ { [ l ] ( G ) }||^2</script><h3 id="风格代价函数"><a href="#风格代价函数" class="headerlink" title="风格代价函数"></a>风格代价函数</h3><h4 id="如何定义一张图片的“风格”"><a href="#如何定义一张图片的“风格”" class="headerlink" title="如何定义一张图片的“风格”"></a>如何定义一张图片的“风格”</h4><p><img src="https://raw.githubusercontent.com/yichenchan/blogimg/master/img/dl_4.4_11.png" alt=""></p>
<p>假设我们使用方框框起来的那一层的激活值来测量“风格”，我们把“风格”定义为这一层的激活值的不同通道之间的相关性。</p>
<h4 id="关于图片风格的解释"><a href="#关于图片风格的解释" class="headerlink" title="关于图片风格的解释"></a>关于图片风格的解释</h4><p><img src="https://raw.githubusercontent.com/yichenchan/blogimg/master/img/dl_4.4_12.png" alt=""></p>
<p>假设红色通道表示红框框起来的特征（那些竖条纹），黄色通道表示黄框框起来的特征（即那些橘红色的图块），那么，红色通道和黄色通道的相关性，可以告诉你在图片中这种竖条纹和橘色图块是否经常同时出现，这是“风格”的一种衡量方式。</p>
<h4 id="风格矩阵"><a href="#风格矩阵" class="headerlink" title="风格矩阵"></a>风格矩阵</h4><p>我们需要过给定的图像计算出风格矩阵，风格矩阵会记录上一张幻灯片中我们提到的所有相关性。</p>
<ul>
<li>$a^{[l]}_{i,j,k}$ 是第 $l$ 层在（i, j, k）这个位置的激活值，i 是高度，j 是宽度，k 是通道</li>
<li>$G^{[l]}$ 是形状为 $n^{[l]}_c×n^{[l]}_c$ 的风格矩阵，$n^{[l]}_c$ 是第 l 层的通道数</li>
</ul>
<script type="math/tex; mode=display">
风格图片的风格矩阵 \ G^{[l](S)}_{kk'}=\sum\limits^{n^{[l]}_H}_{i=1}\sum\limits^{n^{[l]}_W}_{j=1}a^{[l](S)}_{i,j,k}a^{[l](S)}_{i,j,k'}</script><script type="math/tex; mode=display">
生成图片的风格矩阵 \ G^{[l](G)}_{kk'}=\sum\limits^{n^{[l]}_H}_{i=1}\sum\limits^{n^{[l]}_W}_{j=1}a^{[l](G)}_{i,j,k}a^{[l](G)}_{i,j,k'}</script><ul>
<li>kk’ 表示第 k 个通道和第 k‘ 个通道的相关性，在风格矩阵的第 k 行第 k’ 列</li>
<li>线性代数中 G 矩阵被称为格拉姆矩阵 gram matrix</li>
</ul>
<h4 id="风格代价函数-1"><a href="#风格代价函数-1" class="headerlink" title="风格代价函数"></a>风格代价函数</h4><script type="math/tex; mode=display">
J _ { \text { style } } ^ { [ l ] } ( S , G ) =\frac { 1 } { \left( 2 n _ { H } ^ { [ l ] } n _ { W } ^ { [ l ] } n _ { C } ^ { [ l ] } \right) ^ { 2 } }||G^{[l](S)}-G^{[l](G)}||^2_F \\ = \frac { 1 } { \left( 2 n _ { H } ^ { [ l ] } n _ { W } ^ { [ l ] } n _ { C } ^ { [ l ] } \right) ^ { 2 } } \sum _ { k } \sum _ { k ^ { \prime } } \left( G _ { k k ^ { \prime } } ^ { [ l ] ( S ) } - G _ { k k ^ { \prime } } ^ { [ l ] ( G ) } \right)^2</script><ul>
<li>$\frac { 1 } { \left( 2 n _ { H } ^ { [ l ] } n _ { W } ^ { [ l ] } n _ { C } ^ { [ l ] } \right) ^ { 2 } }$ 是不重要的标准化系数</li>
</ul>
<p>如果我们需要将不同层的风格代价函数都考虑进去，那么式子变成：</p>
<script type="math/tex; mode=display">
J _ { \text { style } } ( S , G ) = \sum\limits _l \lambda^{[l]}J _ { \text { style } } ^ { [ l ] } ( S , G )</script><ul>
<li>$\lambda$ 为一个可调整的超参数</li>
</ul>
<h2 id="1D-和-3D-卷积"><a href="#1D-和-3D-卷积" class="headerlink" title="1D 和 3D 卷积"></a>1D 和 3D 卷积</h2><h3 id="2D-到-1D-的推广"><a href="#2D-到-1D-的推广" class="headerlink" title="2D 到 1D 的推广"></a>2D 到 1D 的推广</h3><p><img src="https://raw.githubusercontent.com/yichenchan/blogimg/master/img/dl_4.4_13.png" alt=""></p>
<h3 id="2D-到-3D-的推广"><a href="#2D-到-3D-的推广" class="headerlink" title="2D 到 3D 的推广"></a>2D 到 3D 的推广</h3><p><img src="https://raw.githubusercontent.com/yichenchan/blogimg/master/img/dl_4.4_14.png" alt=""></p>
</div></article><div class="post-meta__tag-list"><a class="post-meta__tags" href="/tags/吴恩达深度学习笔记/">吴恩达深度学习笔记</a><a class="post-meta__tags" href="/tags/AI/">AI</a><a class="post-meta__tags" href="/tags/cnn/">cnn</a><a class="post-meta__tags" href="/tags/人脸识别/">人脸识别</a></div><div class="post-qr-code"><div class="post-qr-code-item"><img class="post-qr-code__img" src="/img/qr1.png"><div class="post-qr-code__desc">微信捐赠</div></div><div class="post-qr-code-item"><img class="post-qr-code__img" src="/img/qr2.jpg"><div class="post-qr-code__desc">支付宝捐赠</div></div></div><div class="social-share"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/social-share.js@1.0.16/dist/css/share.min.css"><script src="https://cdn.jsdelivr.net/npm/social-share.js@1.0.16/dist/js/social-share.min.js"></script><nav id="pagination"><div class="prev-post pull-left"><a href="/2018/11/06/吴恩达机器学习c4w4编程作业/"><i class="fa fa-chevron-left">  </i><span>coursera 吴恩达深度学习 Specialization 编程作业（course 4 week 4）</span></a></div><div class="next-post pull-right"><a href="/2018/10/25/吴恩达机器学习c4w3编程作业/"><span>coursera 吴恩达深度学习 Specialization 编程作业（course 4 week 3）</span><i class="fa fa-chevron-right"></i></a></div></nav><div class="post-adv"><iframe frameborder="no" border="0" marginwidth="0" marginheight="0" width=530 height=86 src="//music.163.com/outchain/player?type=2&id=566993785&auto=1&height=66"></iframe></div><div id="lv-container" data-id="city" data-uid="MTAyMC8zODM1Mi8xNDg4MA=="><script>(function(d, s) {
    var j, e = d.getElementsByTagName(s)[0];
    if (typeof LivereTower === 'function') { return; }
    j = d.createElement(s);
    j.src = 'https://cdn-city.livere.com/js/embed.dist.js';
    j.async = true;
    e.parentNode.insertBefore(j, e);
})(document, 'script');</script></div></div></div><footer><div class="layout" id="footer"><div class="copyright">&copy;2018 By 陈艺琛</div><div class="framework-info"><span>驱动 - </span><a href="http://hexo.io"><span>Hexo</span></a><span class="footer-separator">|</span><span>主题 - </span><a href="https://github.com/Molunerfinn/hexo-theme-melody"><span>Melody</span></a></div><div class="footer_custom_text">这里是我的一亩自耕田，记录自己的学习过程，生活随想和读书笔记，感谢您的参观！</div><div class="busuanzi"><script async src="//dn-lbstatics.qbox.me/busuanzi/2.3/busuanzi.pure.mini.js"></script><span id="busuanzi_container_page_pv"><i class="fa fa-file-o"></i><span id="busuanzi_value_page_pv"></span><span></span></span></div></div></footer><i class="fa fa-arrow-up" id="go-up" aria-hidden="true"></i><script src="/js/third-party/anime.min.js"></script><script src="/js/third-party/jquery.min.js"></script><script src="/js/third-party/jquery.fancybox.min.js"></script><script src="/js/third-party/velocity.min.js"></script><script src="/js/third-party/velocity.ui.min.js"></script><script src="/js/utils.js?version=1.5.6"></script><script src="/js/fancybox.js?version=1.5.6"></script><script src="/js/sidebar.js?version=1.5.6"></script><script src="/js/copy.js?version=1.5.6"></script><script src="/js/fireworks.js?version=1.5.6"></script><script src="/js/transition.js?version=1.5.6"></script><script src="/js/scroll.js?version=1.5.6"></script><script src="/js/head.js?version=1.5.6"></script><script type="text/x-mathjax-config">MathJax.Hub.Config({
  tex2jax: {
    inlineMath: [ ['$','$'], ["\\(","\\)"]  ],
    processEscapes: true,
    skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
  },
  CommonHTML: {
    linebreaks: { automatic: true, width: "90% container" }
  },
  "HTML-CSS": { 
    linebreaks: { automatic: true, width: "90% container" }
  },
  "SVG": { 
    linebreaks: { automatic: true, width: "90% container" }
  }
});
</script><script type="text/x-mathjax-config">MathJax.Hub.Queue(function() {
  var all = MathJax.Hub.getAllJax(), i;
  for (i=0; i < all.length; i += 1) {
    all[i].SourceElement().parentNode.className += ' has-jax';
  }
});
</script><script src="https://cdn.bootcss.com/mathjax/2.7.2/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script><script src="/js/search/local-search.js"></script><div class="search-dialog" id="local-search"><div class="search-dialog__title" id="local-search-title">本地搜索</div><div id="local-input-panel"><div id="local-search-input"><div class="local-search-box"><input class="local-search-box--input" placeholder="搜索文章"></div></div></div><hr><div id="local-search-results"><div id="local-hits"></div><div id="local-stats"><div class="local-search-stats__hr" id="hr"><span>由</span> <a href="https://github.com/wzpan/hexo-generator-search" style="color:#49B1F5;">hexo-generator-search</a>
 <span>提供支持</span></div></div></div><span class="search-close-button"><i class="fa fa-times"></i></span></div><div class="search-mask"></div></body></html>