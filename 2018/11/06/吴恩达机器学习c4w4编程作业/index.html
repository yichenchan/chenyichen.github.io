<!DOCTYPE html><html lang="zh-Hans"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"><meta name="description" content="coursera 吴恩达深度学习 Specialization 编程作业（course 4 week 4）"><meta name="keywords" content="吴恩达深度学习笔记,AI,cnn,人脸识别"><meta name="author" content="陈艺琛,undefined"><meta name="copyright" content="陈艺琛"><title>coursera 吴恩达深度学习 Specialization 编程作业（course 4 week 4） | 艺琛的 Livehouse</title><link rel="shortcut icon" href="/img/logo1.png"><link rel="stylesheet" href="/css/index.css?version=1.5.6"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/font-awesome@4.7.0/css/font-awesome.min.css?version=1.5.6"><link rel="dns-prefetch" href="https://cdn.staticfile.org"><link rel="dns-prefetch" href="https://cdn.bootcss.com"><link rel="dns-prefetch" href="https://creativecommons.org"><link rel="dns-prefetch" href="https://hm.baidu.com"><script>var _hmt = _hmt || [];
(function() {
  var hm = document.createElement("script");
  hm.src = "https://hm.baidu.com/hm.js?20c8efd323cd63b9f6bf846113eb6f60";
  var s = document.getElementsByTagName("script")[0]; 
  s.parentNode.insertBefore(hm, s);
})();</script><script>var GLOBAL_CONFIG = { 
  root: '/',
  algolia: undefined,
  localSearch: {"path":"search.xml","languages":{"hits_empty":"找不到您查询的内容:${query}"}},
  copy: {
    success: '复制成功',
    error: '复制错误',
    noSupport: '浏览器不支持'
  }
} </script></head><body><canvas class="fireworks"></canvas><i class="fa fa-arrow-right" id="toggle-sidebar" aria-hidden="true"></i><div id="sidebar"><div class="toggle-sidebar-info text-center"><span data-toggle="切换文章详情">切换站点概览</span><hr></div><div class="sidebar-toc"><div class="sidebar-toc__title">目录</div><div class="sidebar-toc__progress"><span class="progress-notice">你已经读了</span><span class="progress-num">0</span><span class="progress-percentage">%</span><div class="sidebar-toc__progress-bar"></div></div><div class="sidebar-toc__content"><ol class="toc"><li class="toc-item toc-level-2"><a class="toc-link" href="#神经风格转换"><span class="toc-number">1.</span> <span class="toc-text">神经风格转换</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#内容损失函数"><span class="toc-number">1.1.</span> <span class="toc-text">内容损失函数</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#风格代价函数"><span class="toc-number">1.2.</span> <span class="toc-text">风格代价函数</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#风格矩阵"><span class="toc-number">1.2.1.</span> <span class="toc-text">风格矩阵</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#风格代价函数-1"><span class="toc-number">1.2.2.</span> <span class="toc-text">风格代价函数</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#总的代价函数"><span class="toc-number">1.2.3.</span> <span class="toc-text">总的代价函数</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#进行训练"><span class="toc-number">1.3.</span> <span class="toc-text">进行训练</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#测试"><span class="toc-number">1.4.</span> <span class="toc-text">测试</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#结论"><span class="toc-number">1.5.</span> <span class="toc-text">结论</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#人脸识别"><span class="toc-number">2.</span> <span class="toc-text">人脸识别</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#三重损失"><span class="toc-number">2.1.</span> <span class="toc-text">三重损失</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#加载预训练模型"><span class="toc-number">2.2.</span> <span class="toc-text">加载预训练模型</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#人脸识别和验证"><span class="toc-number">2.3.</span> <span class="toc-text">人脸识别和验证</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#人脸检验"><span class="toc-number">2.3.1.</span> <span class="toc-text">人脸检验</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#人脸识别-1"><span class="toc-number">2.3.2.</span> <span class="toc-text">人脸识别</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#算法的改进"><span class="toc-number">2.4.</span> <span class="toc-text">算法的改进</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#结论-1"><span class="toc-number">2.5.</span> <span class="toc-text">结论</span></a></li></ol></li></ol></div></div><div class="author-info hide"><div class="author-info__avatar text-center"><img src="/img/avater.jpg"></div><div class="author-info__name text-center">陈艺琛</div><div class="author-info__description text-center">a student of HITsz————坚持滑板，热爱摇滚，偶尔弹吉他，喜欢阅读，抽空打游戏，在AI小白之路上踽踽独行。</div><div class="follow-button"><a href="https://web.okjike.com/user/9e0ec001-4bb6-4cab-af94-ea8b2f6067ef/post" target="_blank">在即刻上关注我</a></div><hr><div class="author-info-articles"><a class="author-info-articles__archives article-meta" href="/archives"><span class="pull-left">文章</span><span class="pull-right">33</span></a><a class="author-info-articles__tags article-meta" href="/tags"><span class="pull-left">标签</span><span class="pull-right">28</span></a><a class="author-info-articles__categories article-meta" href="/categories"><span class="pull-left">分类</span><span class="pull-right">3</span></a></div><hr><div class="author-info-links"><div class="author-info-links__title text-center">友链</div><a class="author-info-links__name text-center" href="https://www.liaoxuefeng.com" target="_blank">廖雪峰的博客</a><a class="author-info-links__name text-center" href="https://mooc.study.163.com/smartSpec/detail/1001319001.htm" target="_blank">网易机器学习公开课</a><a class="author-info-links__name text-center" href="https://developers.google.com/machine-learning/crash-course/?hl=zh-cn" target="_blank">谷歌机器学习速成</a><a class="author-info-links__name text-center" href="http://www.hitsz.edu.cn/index.html" target="_blank">哈工大深圳主页</a></div></div></div><div id="content-outer"><div id="top-container" style="background-image: url(https://raw.githubusercontent.com/yichenchan/blogimg/master/img/dl_topimg.png)"><div id="page-header"><span class="pull-left"> <a id="site-name" href="/">艺琛的 Livehouse</a></span><i class="fa fa-bars toggle-menu pull-right" aria-hidden="true"></i><span class="pull-right menus"><a class="site-page social-icon search"><i class="fa fa-search"></i><span> 搜索</span></a><a class="site-page" href="/">主页</a><a class="site-page" href="/categories/学习笔记">学习笔记</a><a class="site-page" href="/categories/读书观影笔记">读书观影笔记</a><a class="site-page" href="/categories/个人随想">个人随想</a><a class="site-page" href="/categories/爱好和生活">爱好和生活</a><a class="site-page" href="/gallery">相册</a><a class="site-page" href="/archives">所有博客</a><a class="site-page" href="/tags">特色标签</a><a class="site-page" href="/about">关于我</a></span></div><div id="post-info"><div id="post-title">coursera 吴恩达深度学习 Specialization 编程作业（course 4 week 4）</div><div id="post-meta"><time class="post-meta__date"><i class="fa fa-calendar" aria-hidden="true"></i> 2018-11-06</time><span class="post-meta__separator">|</span><i class="fa fa-inbox post-meta__icon" aria-hidden="true"></i><a class="post-meta__categories" href="/categories/学习笔记/">学习笔记</a></div></div></div><div class="layout" id="content-inner"><article id="post"><div class="article-container" id="post-content"><h2 id="神经风格转换"><a href="#神经风格转换" class="headerlink" title="神经风格转换"></a>神经风格转换</h2><p>先引入需要的包：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">import</span> sys</span><br><span class="line"><span class="keyword">import</span> scipy.io</span><br><span class="line"><span class="keyword">import</span> scipy.misc</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">from</span> matplotlib.pyplot <span class="keyword">import</span> imshow</span><br><span class="line"><span class="keyword">from</span> PIL <span class="keyword">import</span> Image</span><br><span class="line"><span class="keyword">from</span> nst_utils <span class="keyword">import</span> *</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"></span><br><span class="line">%matplotlib inline</span><br></pre></td></tr></table></figure>
<a id="more"></a>
<p>使用一个预先训练好的 19 层的 VGG-19 网络进行迁移学习，下面加载预训练模型：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">model = load_vgg_model(<span class="string">"pretrained-model/imagenet-vgg-verydeep-19.mat"</span>)</span><br><span class="line">print(model)</span><br></pre></td></tr></table></figure>
<ul>
<li><p>load_vgg_model() 函数为</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">CONFIG</span>:</span></span><br><span class="line">    IMAGE_WIDTH = <span class="number">400</span></span><br><span class="line">    IMAGE_HEIGHT = <span class="number">300</span></span><br><span class="line">    COLOR_CHANNELS = <span class="number">3</span></span><br><span class="line">    NOISE_RATIO = <span class="number">0.6</span></span><br><span class="line">    MEANS = np.array([<span class="number">123.68</span>, <span class="number">116.779</span>, <span class="number">103.939</span>]).reshape((<span class="number">1</span>,<span class="number">1</span>,<span class="number">1</span>,<span class="number">3</span>)) </span><br><span class="line">    VGG_MODEL = <span class="string">'pretrained-model/imagenet-vgg-verydeep-19.mat'</span> <span class="comment"># Pick the VGG 19-layer model by from the paper "Very Deep Convolutional Networks for Large-Scale Image Recognition".</span></span><br><span class="line">    STYLE_IMAGE = <span class="string">'images/stone_style.jpg'</span> <span class="comment"># Style image to use.</span></span><br><span class="line">    CONTENT_IMAGE = <span class="string">'images/content300.jpg'</span> <span class="comment"># Content image to use.</span></span><br><span class="line">    OUTPUT_DIR = <span class="string">'output/'</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">load_vgg_model</span><span class="params">(path)</span>:</span></span><br><span class="line">    <span class="string">"""</span></span><br><span class="line"><span class="string">    Returns a model for the purpose of 'painting' the picture.</span></span><br><span class="line"><span class="string">    Takes only the convolution layer weights and wrap using the TensorFlow</span></span><br><span class="line"><span class="string">    Conv2d, Relu and AveragePooling layer. VGG actually uses maxpool but</span></span><br><span class="line"><span class="string">    the paper indicates that using AveragePooling yields better results.</span></span><br><span class="line"><span class="string">    The last few fully connected layers are not used.</span></span><br><span class="line"><span class="string">    Here is the detailed configuration of the VGG model:</span></span><br><span class="line"><span class="string">        0 is conv1_1 (3, 3, 3, 64)</span></span><br><span class="line"><span class="string">        1 is relu</span></span><br><span class="line"><span class="string">        2 is conv1_2 (3, 3, 64, 64)</span></span><br><span class="line"><span class="string">        3 is relu    </span></span><br><span class="line"><span class="string">        4 is maxpool</span></span><br><span class="line"><span class="string">        5 is conv2_1 (3, 3, 64, 128)</span></span><br><span class="line"><span class="string">        6 is relu</span></span><br><span class="line"><span class="string">        7 is conv2_2 (3, 3, 128, 128)</span></span><br><span class="line"><span class="string">        8 is relu</span></span><br><span class="line"><span class="string">        9 is maxpool</span></span><br><span class="line"><span class="string">        10 is conv3_1 (3, 3, 128, 256)</span></span><br><span class="line"><span class="string">        11 is relu</span></span><br><span class="line"><span class="string">        12 is conv3_2 (3, 3, 256, 256)</span></span><br><span class="line"><span class="string">        13 is relu</span></span><br><span class="line"><span class="string">        14 is conv3_3 (3, 3, 256, 256)</span></span><br><span class="line"><span class="string">        15 is relu</span></span><br><span class="line"><span class="string">        16 is conv3_4 (3, 3, 256, 256)</span></span><br><span class="line"><span class="string">        17 is relu</span></span><br><span class="line"><span class="string">        18 is maxpool</span></span><br><span class="line"><span class="string">        19 is conv4_1 (3, 3, 256, 512)</span></span><br><span class="line"><span class="string">        20 is relu</span></span><br><span class="line"><span class="string">        21 is conv4_2 (3, 3, 512, 512)</span></span><br><span class="line"><span class="string">        22 is relu</span></span><br><span class="line"><span class="string">        23 is conv4_3 (3, 3, 512, 512)</span></span><br><span class="line"><span class="string">        24 is relu</span></span><br><span class="line"><span class="string">        25 is conv4_4 (3, 3, 512, 512)</span></span><br><span class="line"><span class="string">        26 is relu</span></span><br><span class="line"><span class="string">        27 is maxpool</span></span><br><span class="line"><span class="string">        28 is conv5_1 (3, 3, 512, 512)</span></span><br><span class="line"><span class="string">        29 is relu</span></span><br><span class="line"><span class="string">        30 is conv5_2 (3, 3, 512, 512)</span></span><br><span class="line"><span class="string">        31 is relu</span></span><br><span class="line"><span class="string">        32 is conv5_3 (3, 3, 512, 512)</span></span><br><span class="line"><span class="string">        33 is relu</span></span><br><span class="line"><span class="string">        34 is conv5_4 (3, 3, 512, 512)</span></span><br><span class="line"><span class="string">        35 is relu</span></span><br><span class="line"><span class="string">        36 is maxpool</span></span><br><span class="line"><span class="string">        37 is fullyconnected (7, 7, 512, 4096)</span></span><br><span class="line"><span class="string">        38 is relu</span></span><br><span class="line"><span class="string">        39 is fullyconnected (1, 1, 4096, 4096)</span></span><br><span class="line"><span class="string">        40 is relu</span></span><br><span class="line"><span class="string">        41 is fullyconnected (1, 1, 4096, 1000)</span></span><br><span class="line"><span class="string">        42 is softmax</span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line">    </span><br><span class="line">    vgg = scipy.io.loadmat(path)</span><br><span class="line"></span><br><span class="line">    vgg_layers = vgg[<span class="string">'layers'</span>]</span><br><span class="line">    </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">_weights</span><span class="params">(layer, expected_layer_name)</span>:</span></span><br><span class="line">        <span class="string">"""</span></span><br><span class="line"><span class="string">        Return the weights and bias from the VGG model for a given layer.</span></span><br><span class="line"><span class="string">        """</span></span><br><span class="line">        wb = vgg_layers[<span class="number">0</span>][layer][<span class="number">0</span>][<span class="number">0</span>][<span class="number">2</span>]</span><br><span class="line">        W = wb[<span class="number">0</span>][<span class="number">0</span>]</span><br><span class="line">        b = wb[<span class="number">0</span>][<span class="number">1</span>]</span><br><span class="line">        layer_name = vgg_layers[<span class="number">0</span>][layer][<span class="number">0</span>][<span class="number">0</span>][<span class="number">0</span>][<span class="number">0</span>]</span><br><span class="line">        <span class="keyword">assert</span> layer_name == expected_layer_name</span><br><span class="line">        <span class="keyword">return</span> W, b</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> W, b</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">_relu</span><span class="params">(conv2d_layer)</span>:</span></span><br><span class="line">        <span class="string">"""</span></span><br><span class="line"><span class="string">        Return the RELU function wrapped over a TensorFlow layer. Expects a</span></span><br><span class="line"><span class="string">        Conv2d layer input.</span></span><br><span class="line"><span class="string">        """</span></span><br><span class="line">        <span class="keyword">return</span> tf.nn.relu(conv2d_layer)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">_conv2d</span><span class="params">(prev_layer, layer, layer_name)</span>:</span></span><br><span class="line">        <span class="string">"""</span></span><br><span class="line"><span class="string">        Return the Conv2D layer using the weights, biases from the VGG</span></span><br><span class="line"><span class="string">        model at 'layer'.</span></span><br><span class="line"><span class="string">        """</span></span><br><span class="line">        W, b = _weights(layer, layer_name)</span><br><span class="line">        W = tf.constant(W)</span><br><span class="line">        b = tf.constant(np.reshape(b, (b.size)))</span><br><span class="line">        <span class="keyword">return</span> tf.nn.conv2d(prev_layer, filter=W, strides=[<span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>], padding=<span class="string">'SAME'</span>) + b</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">_conv2d_relu</span><span class="params">(prev_layer, layer, layer_name)</span>:</span></span><br><span class="line">        <span class="string">"""</span></span><br><span class="line"><span class="string">        Return the Conv2D + RELU layer using the weights, biases from the VGG</span></span><br><span class="line"><span class="string">        model at 'layer'.</span></span><br><span class="line"><span class="string">        """</span></span><br><span class="line">        <span class="keyword">return</span> _relu(_conv2d(prev_layer, layer, layer_name))</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">_avgpool</span><span class="params">(prev_layer)</span>:</span></span><br><span class="line">        <span class="string">"""</span></span><br><span class="line"><span class="string">        Return the AveragePooling layer.</span></span><br><span class="line"><span class="string">        """</span></span><br><span class="line">        <span class="keyword">return</span> tf.nn.avg_pool(prev_layer, ksize=[<span class="number">1</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">1</span>], strides=[<span class="number">1</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">1</span>], padding=<span class="string">'SAME'</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Constructs the graph model.</span></span><br><span class="line">    graph = &#123;&#125;</span><br><span class="line">    <span class="comment"># 此处将输入作为 variable，使得优化器知道更新其参数</span></span><br><span class="line">    graph[<span class="string">'input'</span>]   = tf.Variable(np.zeros((<span class="number">1</span>, CONFIG.IMAGE_HEIGHT, CONFIG.IMAGE_WIDTH, CONFIG.COLOR_CHANNELS)), dtype = <span class="string">'float32'</span>)</span><br><span class="line">    graph[<span class="string">'conv1_1'</span>]  = _conv2d_relu(graph[<span class="string">'input'</span>], <span class="number">0</span>, <span class="string">'conv1_1'</span>)</span><br><span class="line">    graph[<span class="string">'conv1_2'</span>]  = _conv2d_relu(graph[<span class="string">'conv1_1'</span>], <span class="number">2</span>, <span class="string">'conv1_2'</span>)</span><br><span class="line">    graph[<span class="string">'avgpool1'</span>] = _avgpool(graph[<span class="string">'conv1_2'</span>])</span><br><span class="line">    graph[<span class="string">'conv2_1'</span>]  = _conv2d_relu(graph[<span class="string">'avgpool1'</span>], <span class="number">5</span>, <span class="string">'conv2_1'</span>)</span><br><span class="line">    graph[<span class="string">'conv2_2'</span>]  = _conv2d_relu(graph[<span class="string">'conv2_1'</span>], <span class="number">7</span>, <span class="string">'conv2_2'</span>)</span><br><span class="line">    graph[<span class="string">'avgpool2'</span>] = _avgpool(graph[<span class="string">'conv2_2'</span>])</span><br><span class="line">    graph[<span class="string">'conv3_1'</span>]  = _conv2d_relu(graph[<span class="string">'avgpool2'</span>], <span class="number">10</span>, <span class="string">'conv3_1'</span>)</span><br><span class="line">    graph[<span class="string">'conv3_2'</span>]  = _conv2d_relu(graph[<span class="string">'conv3_1'</span>], <span class="number">12</span>, <span class="string">'conv3_2'</span>)</span><br><span class="line">    graph[<span class="string">'conv3_3'</span>]  = _conv2d_relu(graph[<span class="string">'conv3_2'</span>], <span class="number">14</span>, <span class="string">'conv3_3'</span>)</span><br><span class="line">    graph[<span class="string">'conv3_4'</span>]  = _conv2d_relu(graph[<span class="string">'conv3_3'</span>], <span class="number">16</span>, <span class="string">'conv3_4'</span>)</span><br><span class="line">    graph[<span class="string">'avgpool3'</span>] = _avgpool(graph[<span class="string">'conv3_4'</span>])</span><br><span class="line">    graph[<span class="string">'conv4_1'</span>]  = _conv2d_relu(graph[<span class="string">'avgpool3'</span>], <span class="number">19</span>, <span class="string">'conv4_1'</span>)</span><br><span class="line">    graph[<span class="string">'conv4_2'</span>]  = _conv2d_relu(graph[<span class="string">'conv4_1'</span>], <span class="number">21</span>, <span class="string">'conv4_2'</span>)</span><br><span class="line">    graph[<span class="string">'conv4_3'</span>]  = _conv2d_relu(graph[<span class="string">'conv4_2'</span>], <span class="number">23</span>, <span class="string">'conv4_3'</span>)</span><br><span class="line">    graph[<span class="string">'conv4_4'</span>]  = _conv2d_relu(graph[<span class="string">'conv4_3'</span>], <span class="number">25</span>, <span class="string">'conv4_4'</span>)</span><br><span class="line">    graph[<span class="string">'avgpool4'</span>] = _avgpool(graph[<span class="string">'conv4_4'</span>])</span><br><span class="line">    graph[<span class="string">'conv5_1'</span>]  = _conv2d_relu(graph[<span class="string">'avgpool4'</span>], <span class="number">28</span>, <span class="string">'conv5_1'</span>)</span><br><span class="line">    graph[<span class="string">'conv5_2'</span>]  = _conv2d_relu(graph[<span class="string">'conv5_1'</span>], <span class="number">30</span>, <span class="string">'conv5_2'</span>)</span><br><span class="line">    graph[<span class="string">'conv5_3'</span>]  = _conv2d_relu(graph[<span class="string">'conv5_2'</span>], <span class="number">32</span>, <span class="string">'conv5_3'</span>)</span><br><span class="line">    graph[<span class="string">'conv5_4'</span>]  = _conv2d_relu(graph[<span class="string">'conv5_3'</span>], <span class="number">34</span>, <span class="string">'conv5_4'</span>)</span><br><span class="line">    graph[<span class="string">'avgpool5'</span>] = _avgpool(graph[<span class="string">'conv5_4'</span>])</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">return</span> graph</span><br></pre></td></tr></table></figure>
</li>
</ul>
<p><img src="https://raw.githubusercontent.com/yichenchan/blogimg/master/img/dl_code_4.4_1.png" alt=""></p>
<p>模型被我们存进了一个 dict，dict 的 key 是每一层的名字，value 是这一层的值。</p>
<p>我们可以对某一层进行赋值，例如对输入进行赋值：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">model[<span class="string">"input"</span>].assign(image)</span><br></pre></td></tr></table></figure>
<p>如果想得到某一层的值，我们可以：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sess.run(model[<span class="string">"conv4_2"</span>])</span><br></pre></td></tr></table></figure>
<h3 id="内容损失函数"><a href="#内容损失函数" class="headerlink" title="内容损失函数"></a>内容损失函数</h3><p>内容损失函数是内容图片前向传播的某一层的激活值 a_C 和生成图片前向传播的某一层的激活值 a_G 之间的差距，一般来说我们选取中间层的激活值更能代表图片的内容。</p>
<script type="math/tex; mode=display">J_{content}(C,G) =  \frac{1}{4 \times n_H \times n_W \times n_C}\sum _{ \text{all entries}} (a^{(C)} - a^{(G)})^2\tag{1}</script><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">compute_content_cost</span><span class="params">(a_C, a_G)</span>:</span></span><br><span class="line">    <span class="string">"""</span></span><br><span class="line"><span class="string">    Computes the content cost</span></span><br><span class="line"><span class="string">    </span></span><br><span class="line"><span class="string">    Arguments:</span></span><br><span class="line"><span class="string">    a_C -- tensor of dimension (1, n_H, n_W, n_C), hidden layer activations representing content of the image C </span></span><br><span class="line"><span class="string">    a_G -- tensor of dimension (1, n_H, n_W, n_C), hidden layer activations representing content of the image G</span></span><br><span class="line"><span class="string">    </span></span><br><span class="line"><span class="string">    Returns: </span></span><br><span class="line"><span class="string">    J_content -- scalar that you compute using equation 1 above.</span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line">    </span><br><span class="line">    <span class="comment"># Retrieve dimensions from a_G (≈1 line)</span></span><br><span class="line">    m, n_H, n_W, n_C = a_G.get_shape().as_list()</span><br><span class="line"></span><br><span class="line">    <span class="comment"># compute the cost with tensorflow (≈1 line)</span></span><br><span class="line">    J_content = (<span class="number">1</span> / (<span class="number">4</span> * n_W * n_H * n_C)) * tf.reduce_sum(tf.square(tf.subtract(a_C_unrolled, a_G_unrolled)))</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">return</span> J_content</span><br></pre></td></tr></table></figure>
<h3 id="风格代价函数"><a href="#风格代价函数" class="headerlink" title="风格代价函数"></a>风格代价函数</h3><h4 id="风格矩阵"><a href="#风格矩阵" class="headerlink" title="风格矩阵"></a>风格矩阵</h4><p>风格矩阵代表了某张图片的风格，用某一层的激活值的格拉姆矩阵表示，也就是这一层各个通道之间的相关性，具体的步骤为：先将某一层激活值展开成二维矩阵，风格矩阵就是这个二维矩阵叉乘它的转置矩阵。</p>
<p><img src="https://raw.githubusercontent.com/yichenchan/blogimg/master/img/dl_code_4.4_2.png" alt=""></p>
<p><img src="https://raw.githubusercontent.com/yichenchan/blogimg/master/img/dl_code_4.4_3.png" alt=""></p>
<p>风格矩阵的斜对角，是某个通道自己和自己的相关性，表示某个通道的活跃程度。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 风格矩阵生成</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">gram_matrix</span><span class="params">(A)</span>:</span></span><br><span class="line">    <span class="string">"""</span></span><br><span class="line"><span class="string">    Argument:</span></span><br><span class="line"><span class="string">    A -- matrix of shape (n_C, n_H*n_W)</span></span><br><span class="line"><span class="string">    </span></span><br><span class="line"><span class="string">    Returns:</span></span><br><span class="line"><span class="string">    GA -- Gram matrix of A, of shape (n_C, n_C)</span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line"></span><br><span class="line">    GA = tf.matmul(A, A, transpose_b=<span class="keyword">True</span>)</span><br><span class="line"> </span><br><span class="line">    <span class="keyword">return</span> GA</span><br></pre></td></tr></table></figure>
<h4 id="风格代价函数-1"><a href="#风格代价函数-1" class="headerlink" title="风格代价函数"></a>风格代价函数</h4><p>对于某一层而言，这一层的风格代价函数是，生成图片在这一层的风格矩阵和风格图片在这一层的风格矩阵的“距离”。</p>
<script type="math/tex; mode=display">J_{style}^{[l]}(S,G) = \frac{1}{4 \times {n_C}^2 \times (n_H \times n_W)^2} \sum _{i=1}^{n_C}\sum_{j=1}^{n_C}(G^{(S)}_{ij} - G^{(G)}_{ij})^2\tag{2}</script><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 某一层的风格代价函数</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">compute_layer_style_cost</span><span class="params">(a_S, a_G)</span>:</span></span><br><span class="line">    <span class="string">"""</span></span><br><span class="line"><span class="string">    Arguments:</span></span><br><span class="line"><span class="string">    a_S -- tensor of dimension (1, n_H, n_W, n_C), hidden layer activations representing style of the image S </span></span><br><span class="line"><span class="string">    a_G -- tensor of dimension (1, n_H, n_W, n_C), hidden layer activations representing style of the image G</span></span><br><span class="line"><span class="string">    </span></span><br><span class="line"><span class="string">    Returns: </span></span><br><span class="line"><span class="string">    J_style_layer -- tensor representing a scalar value, style cost defined above by equation (2)</span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># Retrieve dimensions from a_G</span></span><br><span class="line">    m, n_H, n_W, n_C = a_G.get_shape().as_list()</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># Reshape the images to have them of shape (n_C, n_H*n_W)</span></span><br><span class="line">    a_S = tf.transpose(tf.reshape(a_S, [n_H*n_W, n_C]))<span class="comment"># tf.reshape 是从最后一个维度开始取数，(n_H, n_W, n_C) 最后一个维度是通道数，也就是说先把第一行第一列的通道数取出</span></span><br><span class="line">    a_G = tf.transpose(tf.reshape(a_G, [n_H*n_W, n_C]))<span class="comment"># 然后按行排列，如果这一行满了 n_C 个则换行，接着取第一行第二列的通道数，接着按行排列，依次类推，所以只能reshape陈</span></span><br><span class="line">                                                       <span class="comment"># 成(n_H*n_W, n_C)形状的向量，然后进行一次转置操作变成 (n_C, n_W*n_H)  </span></span><br><span class="line">    <span class="comment"># Computing gram_matrices for both images S and G </span></span><br><span class="line">    GS = gram_matrix(a_S)</span><br><span class="line">    GG = gram_matrix(a_G)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Computing the loss </span></span><br><span class="line">    J_style_layer = (<span class="number">1</span> / (<span class="number">4</span> * (n_C ** <span class="number">2</span>) * (n_H*n_W) ** <span class="number">2</span>)) * tf.reduce_sum(tf.square(tf.subtract(GS,GG)))</span><br><span class="line">  </span><br><span class="line">    <span class="keyword">return</span> J_style_layer</span><br></pre></td></tr></table></figure>
<p>最后总的风格代价函数是每一层的风格代价值用不同的权重组合起来，权重存放在一个字典里：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">STYLE_LAYERS = [</span><br><span class="line">    (<span class="string">'conv1_1'</span>, <span class="number">0.2</span>),</span><br><span class="line">    (<span class="string">'conv2_1'</span>, <span class="number">0.2</span>),</span><br><span class="line">    (<span class="string">'conv3_1'</span>, <span class="number">0.2</span>),</span><br><span class="line">    (<span class="string">'conv4_1'</span>, <span class="number">0.2</span>),</span><br><span class="line">    (<span class="string">'conv5_1'</span>, <span class="number">0.2</span>)]</span><br></pre></td></tr></table></figure>
<p>加上权重之后总的风格代价函数为：</p>
<script type="math/tex; mode=display">
J_{style}(S,G) = \sum_{l} \lambda^{[l]} J^{[l]}_{style}(S,G)</script><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">compute_style_cost</span><span class="params">(model, STYLE_LAYERS)</span>:</span></span><br><span class="line">    <span class="string">"""</span></span><br><span class="line"><span class="string">    Computes the overall style cost from several chosen layers</span></span><br><span class="line"><span class="string">    </span></span><br><span class="line"><span class="string">    Arguments:</span></span><br><span class="line"><span class="string">    model -- our tensorflow model</span></span><br><span class="line"><span class="string">    STYLE_LAYERS -- A python list containing:</span></span><br><span class="line"><span class="string">                        - the names of the layers we would like to extract style from</span></span><br><span class="line"><span class="string">                        - a coefficient for each of them</span></span><br><span class="line"><span class="string">    </span></span><br><span class="line"><span class="string">    Returns: </span></span><br><span class="line"><span class="string">    J_style -- tensor representing a scalar value, style cost defined above by equation (2)</span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line">    </span><br><span class="line">    <span class="comment"># initialize the overall style cost</span></span><br><span class="line">    J_style = <span class="number">0</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> layer_name, coeff <span class="keyword">in</span> STYLE_LAYERS:</span><br><span class="line"></span><br><span class="line">        <span class="comment"># Select the output tensor of the currently selected layer</span></span><br><span class="line">        out = model[layer_name]</span><br><span class="line"></span><br><span class="line">        <span class="comment"># Set a_S to be the hidden layer activation from the layer we have selected, by running the session on out</span></span><br><span class="line">        a_S = sess.run(out)	<span class="comment"># 先对 a_S 进行赋值</span></span><br><span class="line"></span><br><span class="line">        <span class="comment"># Set a_G to be the hidden layer activation from same layer. Here, a_G references model[layer_name] </span></span><br><span class="line">        <span class="comment"># and isn't evaluated yet. Later in the code, we'll assign the image G as the model input, so that</span></span><br><span class="line">        <span class="comment"># when we run the session, this will be the activations drawn from the appropriate layer, with G as input.</span></span><br><span class="line">        a_G = out 	<span class="comment"># 由于 a_G 是最后 assign 进模型，我们先不赋值</span></span><br><span class="line">        </span><br><span class="line">        <span class="comment"># Compute style_cost for the current layer</span></span><br><span class="line">        J_style_layer = compute_layer_style_cost(a_S, a_G)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># Add coeff * J_style_layer of this layer to overall style cost</span></span><br><span class="line">        J_style += coeff * J_style_layer</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> J_style</span><br></pre></td></tr></table></figure>
<h4 id="总的代价函数"><a href="#总的代价函数" class="headerlink" title="总的代价函数"></a>总的代价函数</h4><script type="math/tex; mode=display">
J(G) = \alpha J_{content}(C,G) + \beta J_{style}(S,G)</script><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">total_cost</span><span class="params">(J_content, J_style, alpha = <span class="number">10</span>, beta = <span class="number">40</span>)</span>:</span></span><br><span class="line">    <span class="string">"""</span></span><br><span class="line"><span class="string">    Computes the total cost function</span></span><br><span class="line"><span class="string">    </span></span><br><span class="line"><span class="string">    Arguments:</span></span><br><span class="line"><span class="string">    J_content -- content cost coded above</span></span><br><span class="line"><span class="string">    J_style -- style cost coded above</span></span><br><span class="line"><span class="string">    alpha -- hyperparameter weighting the importance of the content cost</span></span><br><span class="line"><span class="string">    beta -- hyperparameter weighting the importance of the style cost</span></span><br><span class="line"><span class="string">    </span></span><br><span class="line"><span class="string">    Returns:</span></span><br><span class="line"><span class="string">    J -- total cost as defined by the formula above.</span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line"></span><br><span class="line">    J = alpha * J_content + beta * J_style</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">return</span> J</span><br></pre></td></tr></table></figure>
<h3 id="进行训练"><a href="#进行训练" class="headerlink" title="进行训练"></a>进行训练</h3><p>步骤为：</p>
<ul>
<li>创建对话</li>
<li>加载内容图片 C</li>
<li>加载风格图片 S</li>
<li>随机初始化需要生成的图片 G</li>
<li>加载预训练模型 VGG</li>
<li>建立 tensorflow 图：<ul>
<li>将内容图片通过 VGG 模型计算内容代价函数</li>
<li>将风格图片通过 VGG 模型计算风格代价函数</li>
<li>计算总代价函数</li>
<li>定义优化器和学习率</li>
</ul>
</li>
<li>初始化计算图用很大的迭代数运行，每一步都更新一次生成图片 G</li>
</ul>
<p>创建对话：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 重设计算图</span></span><br><span class="line">tf.reset_default_graph()</span><br><span class="line"></span><br><span class="line"><span class="comment"># 开启交互式对话，在没有指定会话对象时也会运行变量，不用 with tf.Session() as sess 这种语句来指明默认会话，它自己就是默认会话，更方便</span></span><br><span class="line">sess = tf.InteractiveSession()</span><br></pre></td></tr></table></figure>
<p>加载内容图片 C 并进行 reshape 和 归一化处理：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">content_image = scipy.misc.imread(<span class="string">"images/1.jpg"</span>)</span><br><span class="line">content_image = reshape_and_normalize_image(content_image)</span><br></pre></td></tr></table></figure>
<ul>
<li><p>归一化函数</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">reshape_and_normalize_image</span><span class="params">(image)</span>:</span></span><br><span class="line">    <span class="string">"""</span></span><br><span class="line"><span class="string">    Reshape and normalize the input image (content or style)</span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line">    </span><br><span class="line">    <span class="comment"># Reshape image to mach expected input of VGG16</span></span><br><span class="line">    image = np.reshape(image, ((<span class="number">1</span>,) + image.shape))	<span class="comment"># (1,)+(400,300,3)=(1,400,300,3)</span></span><br><span class="line">    </span><br><span class="line">    <span class="comment"># Substract the mean to match the expected input of VGG16</span></span><br><span class="line">    image = image - CONFIG.MEANS</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">return</span> image</span><br></pre></td></tr></table></figure>
</li>
</ul>
<p>加载风格图片 S 并进行归一化处理：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">style_image = scipy.misc.imread(<span class="string">"images/2.jpg"</span>)</span><br><span class="line">style_image = reshape_and_normalize_image(style_image)</span><br></pre></td></tr></table></figure>
<p>现在用噪音初始化生成图片 G，虽然每个像素是随机的噪声，但还是与内容图片 C 相关，噪声和 C 以一定的权重叠加，使得在更新 G 的像素时能更快地匹配到内容图片。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">generated_image = generate_noise_image(content_image)</span><br><span class="line">imshow(generated_image[<span class="number">0</span>])</span><br></pre></td></tr></table></figure>
<ul>
<li><p>生成噪声的函数</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">generate_noise_image</span><span class="params">(content_image, noise_ratio = CONFIG.NOISE_RATIO)</span>:</span></span><br><span class="line">    <span class="string">"""</span></span><br><span class="line"><span class="string">    Generates a noisy image by adding random noise to the content_image</span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line">    </span><br><span class="line">    <span class="comment"># Generate a random noise_image</span></span><br><span class="line">    noise_image = np.random.uniform(<span class="number">-20</span>, <span class="number">20</span>, (<span class="number">1</span>, CONFIG.IMAGE_HEIGHT, CONFIG.IMAGE_WIDTH, CONFIG.COLOR_CHANNELS)).astype(<span class="string">'float32'</span>)</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># Set the input_image to be a weighted average of the content_image and a noise_image</span></span><br><span class="line">    input_image = noise_image * noise_ratio + content_image * (<span class="number">1</span> - noise_ratio)</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">return</span> input_image</span><br></pre></td></tr></table></figure>
</li>
</ul>
<p><img src="https://raw.githubusercontent.com/yichenchan/blogimg/master/img/dl_code_4.4_4.png" alt=""></p>
<p>加载预训练模型：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">model = load_vgg_model(<span class="string">"pretrained-model/imagenet-vgg-verydeep-19.mat"</span>)</span><br></pre></td></tr></table></figure>
<p>构建计算图：</p>
<ol>
<li><p>选取某一层计算内容代价函数</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Assign the content image to be the input of the VGG model.  </span></span><br><span class="line">sess.run(model[<span class="string">'input'</span>].assign(content_image))</span><br><span class="line"></span><br><span class="line"><span class="comment"># Select the output tensor of layer conv4_2</span></span><br><span class="line">out = model[<span class="string">'conv4_2'</span>]</span><br><span class="line"></span><br><span class="line"><span class="comment"># Set a_C to be the hidden layer activation from the layer we have selected</span></span><br><span class="line">a_C = sess.run(out)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Set a_G to be the hidden layer activation from same layer. Here, a_G references model['conv4_2'] </span></span><br><span class="line"><span class="comment"># and isn't evaluated yet. Later in the code, we'll assign the image G as the model input, so that</span></span><br><span class="line"><span class="comment"># when we run the session, this will be the activations drawn from the appropriate layer, with G as input.</span></span><br><span class="line">a_G = out</span><br><span class="line"></span><br><span class="line"><span class="comment"># Compute the content cost</span></span><br><span class="line">J_content = compute_content_cost(a_C, a_G)</span><br></pre></td></tr></table></figure>
</li>
<li><p>计算风格代价函数</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Assign the input of the model to be the "style" image </span></span><br><span class="line">sess.run(model[<span class="string">'input'</span>].assign(style_image))</span><br><span class="line"></span><br><span class="line"><span class="comment"># Compute the style cost</span></span><br><span class="line">J_style = compute_style_cost(model, STYLE_LAYERS)</span><br></pre></td></tr></table></figure>
</li>
<li><p>计算总的代价函数</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 总代价函数</span></span><br><span class="line">J = total_cost(J_content, J_style, alpha = <span class="number">10</span>, beta = <span class="number">80</span>)</span><br></pre></td></tr></table></figure>
</li>
<li><p>定义优化器</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># define optimizer</span></span><br><span class="line">optimizer = tf.train.AdamOptimizer(<span class="number">2.0</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># define train_step，选择优化对象，总代价函数 J</span></span><br><span class="line">train_step = optimizer.minimize(J)</span><br></pre></td></tr></table></figure>
</li>
</ol>
<p>下面进行训练：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">model_nn</span><span class="params">(sess, input_image, num_iterations = <span class="number">200</span>)</span>:</span></span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 初始化全局变量</span></span><br><span class="line">    tf.global_variables_initializer().run()</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 输入图片 G 是一个变量，使用 assign 对其进行赋值</span></span><br><span class="line">    sess.run(model[<span class="string">'input'</span>].assign(input_image))</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(num_iterations):</span><br><span class="line">    </span><br><span class="line">        <span class="comment"># 运行优化器，更新图片 G 的参数</span></span><br><span class="line">        sess.run(train_step)</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 获得生成图片的值</span></span><br><span class="line">        generated_image = sess.run(model[<span class="string">'input'</span>])</span><br><span class="line"></span><br><span class="line">        <span class="comment"># Print every 20 iteration.</span></span><br><span class="line">        <span class="keyword">if</span> i%<span class="number">20</span> == <span class="number">0</span>:</span><br><span class="line">            Jt, Jc, Js = sess.run([J, J_content, J_style])</span><br><span class="line">            print(<span class="string">"Iteration "</span> + str(i) + <span class="string">" :"</span>)</span><br><span class="line">            print(<span class="string">"total cost = "</span> + str(Jt))</span><br><span class="line">            print(<span class="string">"content cost = "</span> + str(Jc))</span><br><span class="line">            print(<span class="string">"style cost = "</span> + str(Js))</span><br><span class="line">            </span><br><span class="line">            <span class="comment"># save current generated image in the "/output" directory</span></span><br><span class="line">            save_image(<span class="string">"output/"</span> + str(i) + <span class="string">".png"</span>, generated_image)</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># save last generated image</span></span><br><span class="line">    save_image(<span class="string">'output/generated_image.jpg'</span>, generated_image)</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">return</span> generated_image</span><br></pre></td></tr></table></figure>
<ul>
<li><p>其中保存图片的函数</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">save_image</span><span class="params">(path, image)</span>:</span></span><br><span class="line">    </span><br><span class="line">    <span class="comment"># Un-normalize the image so that it looks good 去归一化</span></span><br><span class="line">    image = image + CONFIG.MEANS</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># Clip and Save the image</span></span><br><span class="line">    image = np.clip(image[<span class="number">0</span>], <span class="number">0</span>, <span class="number">255</span>).astype(<span class="string">'uint8'</span>)	<span class="comment"># 这一句将元素的值限制在 0~255 之间</span></span><br><span class="line">    scipy.misc.imsave(path, image)</span><br></pre></td></tr></table></figure>
</li>
</ul>
<h3 id="测试"><a href="#测试" class="headerlink" title="测试"></a>测试</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">model_nn(sess, generated_image)</span><br><span class="line">result_image = scipy.misc.imread(<span class="string">"output/generated_image.jpg"</span>)</span><br><span class="line">imshow(result_image)</span><br></pre></td></tr></table></figure>
<p><img src="https://raw.githubusercontent.com/yichenchan/blogimg/master/img/dl_code_4.4_5.png" alt=""></p>
<h3 id="结论"><a href="#结论" class="headerlink" title="结论"></a>结论</h3><p>What you should remember:</p>
<ul>
<li>Neural Style Transfer is an algorithm that given a content image C and a style image S can generate an artistic image</li>
<li>It uses representations (hidden layer activations) based on a pretrained ConvNet. </li>
<li>The content cost function is computed using one hidden layer’s activations.</li>
<li>The style cost function for one layer is computed using the Gram matrix of that layer’s activations. The overall style cost function is obtained using several hidden layers.</li>
<li>Optimizing the total cost function results in synthesizing new images. </li>
</ul>
<h2 id="人脸识别"><a href="#人脸识别" class="headerlink" title="人脸识别"></a>人脸识别</h2><ul>
<li>使用三重损失函数</li>
<li>使用预训练模型来对人脸图片进行编码</li>
<li>使用这些编码来实现人脸验证和人脸识别</li>
</ul>
<p>照例先引入需要的包：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> keras.models <span class="keyword">import</span> Sequential</span><br><span class="line"><span class="keyword">from</span> keras.layers <span class="keyword">import</span> Conv2D, ZeroPadding2D, Activation, Input, concatenate</span><br><span class="line"><span class="keyword">from</span> keras.models <span class="keyword">import</span> Model</span><br><span class="line"><span class="keyword">from</span> keras.layers.normalization <span class="keyword">import</span> BatchNormalization</span><br><span class="line"><span class="keyword">from</span> keras.layers.pooling <span class="keyword">import</span> MaxPooling2D, AveragePooling2D</span><br><span class="line"><span class="keyword">from</span> keras.layers.merge <span class="keyword">import</span> Concatenate</span><br><span class="line"><span class="keyword">from</span> keras.layers.core <span class="keyword">import</span> Lambda, Flatten, Dense</span><br><span class="line"><span class="keyword">from</span> keras.initializers <span class="keyword">import</span> glorot_uniform</span><br><span class="line"><span class="keyword">from</span> keras.engine.topology <span class="keyword">import</span> Layer</span><br><span class="line"><span class="keyword">from</span> keras <span class="keyword">import</span> backend <span class="keyword">as</span> K</span><br><span class="line">K.set_image_data_format(<span class="string">'channels_first'</span>)	<span class="comment"># 将图片格式设置为通道数在前</span></span><br><span class="line"><span class="keyword">import</span> cv2</span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">from</span> numpy <span class="keyword">import</span> genfromtxt</span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"><span class="keyword">from</span> fr_utils <span class="keyword">import</span> *</span><br><span class="line"><span class="keyword">from</span> inception_blocks_v2 <span class="keyword">import</span> *</span><br><span class="line"></span><br><span class="line">%matplotlib inline</span><br><span class="line">%load_ext autoreload</span><br><span class="line">%autoreload <span class="number">2</span></span><br><span class="line"></span><br><span class="line">np.set_printoptions(threshold=np.nan)</span><br></pre></td></tr></table></figure>
<h3 id="三重损失"><a href="#三重损失" class="headerlink" title="三重损失"></a>三重损失</h3><p>由于我们采用预训练模型，不需要对三重损失进行优化，但是还是有必要知道如何实现。</p>
<script type="math/tex; mode=display">
\mathcal{J} = \sum^{m}_{i=1} \large[ \small \mid \mid f(A^{(i)}) - f(P^{(i)}) \mid \mid_2^2 - \mid \mid f(A^{(i)}) - f(N^{(i)}) \mid \mid_2^2+ \alpha \large ] \small_+</script><ul>
<li>A 为锚照片，P 为正例，N 为反例，$\alpha$ 是一个裕度</li>
<li>f() 表示照片经过模型的输出向量，也就是编码</li>
<li>$[ \ \  ]_+$表示取和 0 相比的较大值</li>
</ul>
<p>为了能在 keras 模型的编译环节使用，我们使用 keras 中损失函数的格式进行自定义 loss 函数：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">triplet_loss</span><span class="params">(y_true, y_pred, alpha = <span class="number">0.2</span>)</span>:</span> </span><br><span class="line">    <span class="string">"""</span></span><br><span class="line"><span class="string">    Implementation of the triplet loss as defined by formula (3)</span></span><br><span class="line"><span class="string">    </span></span><br><span class="line"><span class="string">    Arguments:</span></span><br><span class="line"><span class="string">    y_true -- y_true 其实没有用，但是在 Keras 中要定义一个损失函数就必须按照这个格式</span></span><br><span class="line"><span class="string">    y_pred -- python list containing three objects:</span></span><br><span class="line"><span class="string">            anchor -- the encodings for the anchor images, of shape (None, 128)</span></span><br><span class="line"><span class="string">            positive -- the encodings for the positive images, of shape (None, 128)</span></span><br><span class="line"><span class="string">            negative -- the encodings for the negative images, of shape (None, 128)</span></span><br><span class="line"><span class="string">    </span></span><br><span class="line"><span class="string">    Returns:</span></span><br><span class="line"><span class="string">    loss -- real number, value of the loss</span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line">    </span><br><span class="line">    anchor, positive, negative = y_pred[<span class="number">0</span>], y_pred[<span class="number">1</span>], y_pred[<span class="number">2</span>]</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># Step 1: Compute the (encoding) distance between the anchor and the positive, you will need to sum over axis=-1</span></span><br><span class="line">    pos_dist = tf.reduce_sum(tf.square(tf.subtract(anchor, positive)), axis = <span class="number">-1</span>)</span><br><span class="line">    <span class="comment"># Step 2: Compute the (encoding) distance between the anchor and the negative, you will need to sum over axis=-1</span></span><br><span class="line">    neg_dist = tf.reduce_sum(tf.square(tf.subtract(anchor, negative)), axis = <span class="number">-1</span>)</span><br><span class="line">    <span class="comment"># Step 3: subtract the two previous distances and add alpha.</span></span><br><span class="line">    basic_loss = pos_dist - neg_dist + alpha</span><br><span class="line">    <span class="comment"># Step 4: Take the maximum of basic_loss and 0.0. Sum over the training examples.</span></span><br><span class="line">    loss = tf.reduce_sum(tf.maximum(basic_loss, <span class="number">0</span>))</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">return</span> loss</span><br></pre></td></tr></table></figure>
<h3 id="加载预训练模型"><a href="#加载预训练模型" class="headerlink" title="加载预训练模型"></a>加载预训练模型</h3><p>我们使用别人训练好的一个 Inception 网络来对图片进行编码。</p>
<ul>
<li>输入形状为 $(m, n_C, n_H, n_W) = (m, 3, 96, 96)$ 的图片</li>
<li>输出形状为 $(m, 128)$ 的图片编码</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">FRmodel = faceRecoModel(input_shape=(<span class="number">3</span>, <span class="number">96</span>, <span class="number">96</span>))</span><br></pre></td></tr></table></figure>
<p>编译模型并加载权重：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">FRmodel.compile(optimizer = <span class="string">'adam'</span>, loss = triplet_loss, metrics = [<span class="string">'accuracy'</span>])</span><br><span class="line">load_weights_from_FaceNet(FRmodel)</span><br></pre></td></tr></table></figure>
<p>具体的函数细节见 <a href="https://github.com/iwantooxxoox" target="_blank" rel="noopener">iwantooxxoox</a> 的 github。</p>
<h3 id="人脸识别和验证"><a href="#人脸识别和验证" class="headerlink" title="人脸识别和验证"></a>人脸识别和验证</h3><p>首先我们要建立一个数据库，里面存放了所有的需要识别或验证的人的照片通过神经网络的编码。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">database = &#123;&#125;</span><br><span class="line">database[<span class="string">"danielle"</span>] = img_to_encoding(<span class="string">"images/danielle.png"</span>, FRmodel)</span><br><span class="line">database[<span class="string">"younes"</span>] = img_to_encoding(<span class="string">"images/younes.jpg"</span>, FRmodel)</span><br><span class="line">database[<span class="string">"tian"</span>] = img_to_encoding(<span class="string">"images/tian.jpg"</span>, FRmodel)</span><br><span class="line">database[<span class="string">"andrew"</span>] = img_to_encoding(<span class="string">"images/andrew.jpg"</span>, FRmodel)</span><br><span class="line">database[<span class="string">"kian"</span>] = img_to_encoding(<span class="string">"images/kian.jpg"</span>, FRmodel)</span><br><span class="line">database[<span class="string">"dan"</span>] = img_to_encoding(<span class="string">"images/dan.jpg"</span>, FRmodel)</span><br><span class="line">database[<span class="string">"sebastiano"</span>] = img_to_encoding(<span class="string">"images/sebastiano.jpg"</span>, FRmodel)</span><br><span class="line">database[<span class="string">"bertrand"</span>] = img_to_encoding(<span class="string">"images/bertrand.jpg"</span>, FRmodel)</span><br><span class="line">database[<span class="string">"kevin"</span>] = img_to_encoding(<span class="string">"images/kevin.jpg"</span>, FRmodel)</span><br><span class="line">database[<span class="string">"felix"</span>] = img_to_encoding(<span class="string">"images/felix.jpg"</span>, FRmodel)</span><br><span class="line">database[<span class="string">"benoit"</span>] = img_to_encoding(<span class="string">"images/benoit.jpg"</span>, FRmodel)</span><br><span class="line">database[<span class="string">"arnaud"</span>] = img_to_encoding(<span class="string">"images/arnaud.jpg"</span>, FRmodel)</span><br></pre></td></tr></table></figure>
<p>其中获取编码的函数：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">img_to_encoding</span><span class="params">(image_path, model)</span>:</span></span><br><span class="line">    img1 = cv2.imread(image_path, <span class="number">1</span>)</span><br><span class="line">    img = img1[...,::<span class="number">-1</span>]</span><br><span class="line">    img = np.around(np.transpose(img, (<span class="number">2</span>,<span class="number">0</span>,<span class="number">1</span>))/<span class="number">255.0</span>, decimals=<span class="number">12</span>)</span><br><span class="line">    x_train = np.array([img])</span><br><span class="line">    embedding = model.predict_on_batch(x_train)</span><br><span class="line">    <span class="keyword">return</span> embedding</span><br></pre></td></tr></table></figure>
<h4 id="人脸检验"><a href="#人脸检验" class="headerlink" title="人脸检验"></a>人脸检验</h4><p>所谓人脸检验就是在识别时提供人脸照片和 ID 号，用来验证是不是本人，1 对 1 的问题。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">verify</span><span class="params">(image_path, identity, database, model)</span>:</span></span><br><span class="line">    <span class="string">"""</span></span><br><span class="line"><span class="string">    Function that verifies if the person on the "image_path" image is "identity".</span></span><br><span class="line"><span class="string">    </span></span><br><span class="line"><span class="string">    Arguments:</span></span><br><span class="line"><span class="string">    image_path -- path to an image</span></span><br><span class="line"><span class="string">    identity -- string, name of the person you'd like to verify the identity. Has to be a resident of the Happy house.</span></span><br><span class="line"><span class="string">    database -- python dictionary mapping names of allowed people's names (strings) to their encodings (vectors).</span></span><br><span class="line"><span class="string">    model -- your Inception model instance in Keras</span></span><br><span class="line"><span class="string">    </span></span><br><span class="line"><span class="string">    Returns:</span></span><br><span class="line"><span class="string">    dist -- distance between the image_path and the image of "identity" in the database.</span></span><br><span class="line"><span class="string">    door_open -- True, if the door should open. False otherwise.</span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># Step 1: Compute the encoding for the image. Use img_to_encoding() see example above. </span></span><br><span class="line">    encoding = img_to_encoding(image_path, model)</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># Step 2: Compute distance with identity's image </span></span><br><span class="line">    dist = np.linalg.norm(encoding - database[identity])</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># Step 3: Open the door if dist &lt; 0.7, else don't open</span></span><br><span class="line">    <span class="keyword">if</span> dist &lt; <span class="number">0.7</span>:</span><br><span class="line">        print(<span class="string">"It's "</span> + str(identity) + <span class="string">", welcome home!"</span>)</span><br><span class="line">        door_open = <span class="keyword">True</span></span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        print(<span class="string">"It's not "</span> + str(identity) + <span class="string">", please go away"</span>)</span><br><span class="line">        door_open = <span class="keyword">False</span></span><br><span class="line">   </span><br><span class="line">    <span class="keyword">return</span> dist, door_open</span><br></pre></td></tr></table></figure>
<h4 id="人脸识别-1"><a href="#人脸识别-1" class="headerlink" title="人脸识别"></a>人脸识别</h4><p>人脸识别不再提供 ID 号，只提供人脸照片，然后与数据库里的编码进行比对，找出与之距离最小的，如果距离小于某个阈值，则我们认定他是数据库中的人。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">who_is_it</span><span class="params">(image_path, database, model)</span>:</span></span><br><span class="line">    <span class="string">"""</span></span><br><span class="line"><span class="string">    Implements face recognition for the happy house by finding who is the person on the image_path image.</span></span><br><span class="line"><span class="string">    </span></span><br><span class="line"><span class="string">    Arguments:</span></span><br><span class="line"><span class="string">    image_path -- path to an image</span></span><br><span class="line"><span class="string">    database -- database containing image encodings along with the name of the person on the image</span></span><br><span class="line"><span class="string">    model -- your Inception model instance in Keras</span></span><br><span class="line"><span class="string">    </span></span><br><span class="line"><span class="string">    Returns:</span></span><br><span class="line"><span class="string">    min_dist -- the minimum distance between image_path encoding and the encodings from the database</span></span><br><span class="line"><span class="string">    identity -- string, the name prediction for the person on image_path</span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line"> </span><br><span class="line">    <span class="comment">## Step 1: Compute the target "encoding" for the image. Use img_to_encoding() see example above.</span></span><br><span class="line">    encoding = img_to_encoding(image_path, model)</span><br><span class="line">    </span><br><span class="line">    <span class="comment">## Step 2: Find the closest encoding，排序算法</span></span><br><span class="line">    </span><br><span class="line">    <span class="comment"># Initialize "min_dist" to a large value, say 100 </span></span><br><span class="line">    min_dist = <span class="number">100</span></span><br><span class="line">    </span><br><span class="line">    <span class="comment"># Loop over the database dictionary's names and encodings.</span></span><br><span class="line">    <span class="keyword">for</span> (name, db_enc) <span class="keyword">in</span> database.items(): <span class="comment"># 如果要迭代 key 和 value 必须加 .item() </span></span><br><span class="line">        </span><br><span class="line">        <span class="comment"># Compute L2 distance between the target "encoding" and the current "emb" from the database.</span></span><br><span class="line">        dist = np.linalg.norm(encoding - db_enc)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># If this distance is less than the min_dist, then set min_dist to dist, and identity to name.</span></span><br><span class="line">        <span class="keyword">if</span> dist &lt; min_dist:</span><br><span class="line">            min_dist = dist</span><br><span class="line">            identity = name</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> min_dist &gt; <span class="number">0.7</span>:</span><br><span class="line">        print(<span class="string">"Not in the database."</span>)</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        <span class="keyword">print</span> (<span class="string">"it's "</span> + str(identity) + <span class="string">", the distance is "</span> + str(min_dist))</span><br><span class="line">        </span><br><span class="line">    <span class="keyword">return</span> min_dist, identity</span><br></pre></td></tr></table></figure>
<h3 id="算法的改进"><a href="#算法的改进" class="headerlink" title="算法的改进"></a>算法的改进</h3><ul>
<li>Put more images of each person (under different lighting conditions, taken on different days, etc.) into the database. Then given a new image, compare the new face to multiple pictures of the person. This would increae accuracy.</li>
<li>Crop the images to just contain the face, and less of the “border” region around the face. This preprocessing removes some of the irrelevant pixels around the face, and also makes the algorithm more robust.</li>
</ul>
<h3 id="结论-1"><a href="#结论-1" class="headerlink" title="结论"></a>结论</h3><ul>
<li>Face verification solves an easier 1:1 matching problem; face recognition addresses a harder 1:K matching problem. </li>
<li>The triplet loss is an effective loss function for training a neural network to learn an encoding of a face image.</li>
<li>The same encoding can be used for verification and recognition. Measuring distances between two images’ encodings allows you to determine whether they are pictures of the same person. </li>
</ul>
</div></article><div class="post-meta__tag-list"><a class="post-meta__tags" href="/tags/吴恩达深度学习笔记/">吴恩达深度学习笔记</a><a class="post-meta__tags" href="/tags/AI/">AI</a><a class="post-meta__tags" href="/tags/cnn/">cnn</a><a class="post-meta__tags" href="/tags/人脸识别/">人脸识别</a></div><div class="post-qr-code"><div class="post-qr-code-item"><img class="post-qr-code__img" src="/img/qr1.png"><div class="post-qr-code__desc">微信捐赠</div></div><div class="post-qr-code-item"><img class="post-qr-code__img" src="/img/qr2.jpg"><div class="post-qr-code__desc">支付宝捐赠</div></div></div><div class="social-share"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/social-share.js@1.0.16/dist/css/share.min.css"><script src="https://cdn.jsdelivr.net/npm/social-share.js@1.0.16/dist/js/social-share.min.js"></script><nav id="pagination"><div class="prev-post pull-left"><a href="/2018/11/08/吴恩达机器学习笔记c5w1/"><i class="fa fa-chevron-left">  </i><span>coursera 吴恩达深度学习 Specialization 笔记（course 5 week 1）—— 循环神经网络 RNN</span></a></div><div class="next-post pull-right"><a href="/2018/11/01/吴恩达机器学习笔记c4w4/"><span>coursera 吴恩达深度学习 Specialization 笔记（course 4 week 4）—— 人脸识别</span><i class="fa fa-chevron-right"></i></a></div></nav><div class="post-adv"><iframe frameborder="no" border="0" marginwidth="0" marginheight="0" width=530 height=86 src="//music.163.com/outchain/player?type=2&id=566993785&auto=1&height=66"></iframe></div><div id="lv-container" data-id="city" data-uid="MTAyMC8zODM1Mi8xNDg4MA=="><script>(function(d, s) {
    var j, e = d.getElementsByTagName(s)[0];
    if (typeof LivereTower === 'function') { return; }
    j = d.createElement(s);
    j.src = 'https://cdn-city.livere.com/js/embed.dist.js';
    j.async = true;
    e.parentNode.insertBefore(j, e);
})(document, 'script');</script></div></div></div><footer><div class="layout" id="footer"><div class="copyright">&copy;2018 By 陈艺琛</div><div class="framework-info"><span>驱动 - </span><a href="http://hexo.io"><span>Hexo</span></a><span class="footer-separator">|</span><span>主题 - </span><a href="https://github.com/Molunerfinn/hexo-theme-melody"><span>Melody</span></a></div><div class="footer_custom_text">这里是我的一亩自耕田，记录自己的学习过程，生活随想和读书笔记，感谢您的参观！</div><div class="busuanzi"><script async src="//dn-lbstatics.qbox.me/busuanzi/2.3/busuanzi.pure.mini.js"></script><span id="busuanzi_container_page_pv"><i class="fa fa-file-o"></i><span id="busuanzi_value_page_pv"></span><span></span></span></div></div></footer><i class="fa fa-arrow-up" id="go-up" aria-hidden="true"></i><script src="/js/third-party/anime.min.js"></script><script src="/js/third-party/jquery.min.js"></script><script src="/js/third-party/jquery.fancybox.min.js"></script><script src="/js/third-party/velocity.min.js"></script><script src="/js/third-party/velocity.ui.min.js"></script><script src="/js/utils.js?version=1.5.6"></script><script src="/js/fancybox.js?version=1.5.6"></script><script src="/js/sidebar.js?version=1.5.6"></script><script src="/js/copy.js?version=1.5.6"></script><script src="/js/fireworks.js?version=1.5.6"></script><script src="/js/transition.js?version=1.5.6"></script><script src="/js/scroll.js?version=1.5.6"></script><script src="/js/head.js?version=1.5.6"></script><script type="text/x-mathjax-config">MathJax.Hub.Config({
  tex2jax: {
    inlineMath: [ ['$','$'], ["\\(","\\)"]  ],
    processEscapes: true,
    skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
  },
  CommonHTML: {
    linebreaks: { automatic: true, width: "90% container" }
  },
  "HTML-CSS": { 
    linebreaks: { automatic: true, width: "90% container" }
  },
  "SVG": { 
    linebreaks: { automatic: true, width: "90% container" }
  }
});
</script><script type="text/x-mathjax-config">MathJax.Hub.Queue(function() {
  var all = MathJax.Hub.getAllJax(), i;
  for (i=0; i < all.length; i += 1) {
    all[i].SourceElement().parentNode.className += ' has-jax';
  }
});
</script><script src="https://cdn.bootcss.com/mathjax/2.7.2/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script><script src="/js/search/local-search.js"></script><div class="search-dialog" id="local-search"><div class="search-dialog__title" id="local-search-title">本地搜索</div><div id="local-input-panel"><div id="local-search-input"><div class="local-search-box"><input class="local-search-box--input" placeholder="搜索文章"></div></div></div><hr><div id="local-search-results"><div id="local-hits"></div><div id="local-stats"><div class="local-search-stats__hr" id="hr"><span>由</span> <a href="https://github.com/wzpan/hexo-generator-search" style="color:#49B1F5;">hexo-generator-search</a>
 <span>提供支持</span></div></div></div><span class="search-close-button"><i class="fa fa-times"></i></span></div><div class="search-mask"></div></body></html>