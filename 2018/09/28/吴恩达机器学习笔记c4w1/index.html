<!DOCTYPE html><html lang="zh-Hans"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"><meta name="description" content="coursera 吴恩达深度学习 Specialization 笔记（course 4 week 1）—— 卷积神经网络基础"><meta name="keywords" content="吴恩达深度学习笔记,AI,cnn"><meta name="author" content="陈艺琛,undefined"><meta name="copyright" content="陈艺琛"><title>coursera 吴恩达深度学习 Specialization 笔记（course 4 week 1）—— 卷积神经网络基础 | 艺琛的 Livehouse</title><link rel="shortcut icon" href="/img/logo1.png"><link rel="stylesheet" href="/css/index.css?version=1.5.6"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/font-awesome@4.7.0/css/font-awesome.min.css?version=1.5.6"><link rel="dns-prefetch" href="https://cdn.staticfile.org"><link rel="dns-prefetch" href="https://cdn.bootcss.com"><link rel="dns-prefetch" href="https://creativecommons.org"><link rel="dns-prefetch" href="https://hm.baidu.com"><script>var _hmt = _hmt || [];
(function() {
  var hm = document.createElement("script");
  hm.src = "https://hm.baidu.com/hm.js?20c8efd323cd63b9f6bf846113eb6f60";
  var s = document.getElementsByTagName("script")[0]; 
  s.parentNode.insertBefore(hm, s);
})();</script><script>var GLOBAL_CONFIG = { 
  root: '/',
  algolia: undefined,
  localSearch: {"path":"search.xml","languages":{"hits_empty":"找不到您查询的内容:${query}"}},
  copy: {
    success: '复制成功',
    error: '复制错误',
    noSupport: '浏览器不支持'
  }
} </script></head><body><canvas class="fireworks"></canvas><i class="fa fa-arrow-right" id="toggle-sidebar" aria-hidden="true"></i><div id="sidebar"><div class="toggle-sidebar-info text-center"><span data-toggle="切换文章详情">切换站点概览</span><hr></div><div class="sidebar-toc"><div class="sidebar-toc__title">目录</div><div class="sidebar-toc__progress"><span class="progress-notice">你已经读了</span><span class="progress-num">0</span><span class="progress-percentage">%</span><div class="sidebar-toc__progress-bar"></div></div><div class="sidebar-toc__content"><ol class="toc"><li class="toc-item toc-level-2"><a class="toc-link" href="#计算机视觉"><span class="toc-number">1.</span> <span class="toc-text">计算机视觉</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#计算机视觉的问题"><span class="toc-number">1.1.</span> <span class="toc-text">计算机视觉的问题</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#计算机视觉的挑战"><span class="toc-number">1.2.</span> <span class="toc-text">计算机视觉的挑战</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#卷积运算-Convolutional-operation"><span class="toc-number">2.</span> <span class="toc-text">卷积运算 (Convolutional operation)</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#引例"><span class="toc-number">2.1.</span> <span class="toc-text">引例</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#更多边缘检测例子"><span class="toc-number">2.2.</span> <span class="toc-text">更多边缘检测例子</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#填充-paddling"><span class="toc-number">2.3.</span> <span class="toc-text">填充 (paddling)</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#卷积运算的一些问题"><span class="toc-number">2.3.1.</span> <span class="toc-text">卷积运算的一些问题</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#怎麽办"><span class="toc-number">2.3.2.</span> <span class="toc-text">怎麽办</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#到底填充多少？——两种卷积"><span class="toc-number">2.3.3.</span> <span class="toc-text">到底填充多少？——两种卷积</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#带步长的-strided-卷积"><span class="toc-number">2.4.</span> <span class="toc-text">带步长的 (strided) 卷积</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#一个提法的纠正"><span class="toc-number">2.5.</span> <span class="toc-text">一个提法的纠正</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#对三维立方体的卷积"><span class="toc-number">2.6.</span> <span class="toc-text">对三维立方体的卷积</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#单过滤器"><span class="toc-number">2.6.1.</span> <span class="toc-text">单过滤器</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#多过滤器"><span class="toc-number">2.6.2.</span> <span class="toc-text">多过滤器</span></a></li></ol></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#单层卷积神经网络"><span class="toc-number">3.</span> <span class="toc-text">单层卷积神经网络</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#引例-1"><span class="toc-number">3.1.</span> <span class="toc-text">引例</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#一层卷积层的参数"><span class="toc-number">3.2.</span> <span class="toc-text">一层卷积层的参数</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#标记符号总结"><span class="toc-number">3.3.</span> <span class="toc-text">标记符号总结</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#深层卷积神经网络"><span class="toc-number">4.</span> <span class="toc-text">深层卷积神经网络</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#引例-2"><span class="toc-number">4.1.</span> <span class="toc-text">引例</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#卷积网络中的层类型"><span class="toc-number">4.2.</span> <span class="toc-text">卷积网络中的层类型</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#池化层-Pooling-Layers"><span class="toc-number">4.3.</span> <span class="toc-text">池化层 (Pooling Layers)</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#识别手写数字的例子"><span class="toc-number">4.4.</span> <span class="toc-text">识别手写数字的例子</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#为什么卷积如此有用"><span class="toc-number">5.</span> <span class="toc-text">为什么卷积如此有用</span></a></li></ol></div></div><div class="author-info hide"><div class="author-info__avatar text-center"><img src="/img/avater.jpg"></div><div class="author-info__name text-center">陈艺琛</div><div class="author-info__description text-center">a student of HITsz————坚持滑板，热爱摇滚，偶尔弹吉他，喜欢阅读，抽空打游戏，在AI小白之路上踽踽独行。</div><div class="follow-button"><a href="https://web.okjike.com/user/9e0ec001-4bb6-4cab-af94-ea8b2f6067ef/post" target="_blank">在即刻上关注我</a></div><hr><div class="author-info-articles"><a class="author-info-articles__archives article-meta" href="/archives"><span class="pull-left">文章</span><span class="pull-right">36</span></a><a class="author-info-articles__tags article-meta" href="/tags"><span class="pull-left">标签</span><span class="pull-right">29</span></a><a class="author-info-articles__categories article-meta" href="/categories"><span class="pull-left">分类</span><span class="pull-right">3</span></a></div><hr><div class="author-info-links"><div class="author-info-links__title text-center">友链</div><a class="author-info-links__name text-center" href="https://www.liaoxuefeng.com" target="_blank">廖雪峰的博客</a><a class="author-info-links__name text-center" href="https://mooc.study.163.com/smartSpec/detail/1001319001.htm" target="_blank">网易机器学习公开课</a><a class="author-info-links__name text-center" href="https://developers.google.com/machine-learning/crash-course/?hl=zh-cn" target="_blank">谷歌机器学习速成</a><a class="author-info-links__name text-center" href="http://www.hitsz.edu.cn/index.html" target="_blank">哈工大深圳主页</a></div></div></div><div id="content-outer"><div id="top-container" style="background-image: url(https://raw.githubusercontent.com/yichenchan/blogimg/master/img/dl_topimg.png)"><div id="page-header"><span class="pull-left"> <a id="site-name" href="/">艺琛的 Livehouse</a></span><i class="fa fa-bars toggle-menu pull-right" aria-hidden="true"></i><span class="pull-right menus"><a class="site-page social-icon search"><i class="fa fa-search"></i><span> 搜索</span></a><a class="site-page" href="/">主页</a><a class="site-page" href="/categories/学习笔记">学习笔记</a><a class="site-page" href="/categories/读书观影笔记">读书观影笔记</a><a class="site-page" href="/categories/个人随想">个人随想</a><a class="site-page" href="/categories/爱好和生活">爱好和生活</a><a class="site-page" href="/gallery">相册</a><a class="site-page" href="/archives">所有博客</a><a class="site-page" href="/tags">特色标签</a><a class="site-page" href="/about">关于我</a></span></div><div id="post-info"><div id="post-title">coursera 吴恩达深度学习 Specialization 笔记（course 4 week 1）—— 卷积神经网络基础</div><div id="post-meta"><time class="post-meta__date"><i class="fa fa-calendar" aria-hidden="true"></i> 2018-09-28</time><span class="post-meta__separator">|</span><i class="fa fa-inbox post-meta__icon" aria-hidden="true"></i><a class="post-meta__categories" href="/categories/学习笔记/">学习笔记</a></div></div></div><div class="layout" id="content-inner"><article id="post"><div class="article-container" id="post-content"><h2 id="计算机视觉"><a href="#计算机视觉" class="headerlink" title="计算机视觉"></a>计算机视觉</h2><h3 id="计算机视觉的问题"><a href="#计算机视觉的问题" class="headerlink" title="计算机视觉的问题"></a>计算机视觉的问题</h3><ul>
<li><p>图像分类：例如猫分类器</p>
</li>
<li><p>物体检测：例如自动驾驶不仅需要识别出图片中是否有车，还要计算出这张图片中汽车的位置</p>
</li>
<li><p>神经风格转换：如下图</p>
<p><img src="https://raw.githubusercontent.com/yichenchan/blogimg/master/img/dl_4.1_1.png" alt=""></p>
</li>
</ul>
<a id="more"></a>
<h3 id="计算机视觉的挑战"><a href="#计算机视觉的挑战" class="headerlink" title="计算机视觉的挑战"></a>计算机视觉的挑战</h3><p>图片的像素可以任意大，输入维度可以任意大，会导致：</p>
<ul>
<li>很难获得足够数据避免过拟合</li>
<li>对计算量和内存的需求很大</li>
</ul>
<p><img src="https://raw.githubusercontent.com/yichenchan/blogimg/master/img/dl_4.1_2.png" alt=""></p>
<h2 id="卷积运算-Convolutional-operation"><a href="#卷积运算-Convolutional-operation" class="headerlink" title="卷积运算 (Convolutional operation)"></a>卷积运算 (Convolutional operation)</h2><h3 id="引例"><a href="#引例" class="headerlink" title="引例"></a>引例</h3><p>假设要检测下图的垂直边缘和水平边缘：</p>
<p><img src="https://raw.githubusercontent.com/yichenchan/blogimg/master/img/dl_4.1_3.png" alt=""></p>
<p>检测垂直边缘可以使用如下方法：</p>
<p><img src="https://raw.githubusercontent.com/yichenchan/blogimg/master/img/dl_4.1_4.png" alt=""></p>
<ul>
<li>左边是某个图像</li>
<li>中间是一个 3×3 的<strong>过滤器 (fliter)</strong>，是一个矩阵，有时也称为<strong>核 (kernel)</strong> </li>
<li><strong>*</strong> 符号表示<strong>卷积运算</strong> </li>
<li>将蓝框中的值逐元素乘以过滤器矩阵的值然后相加得到第一个结果 -5，下面的以此类推</li>
</ul>
<p><img src="https://raw.githubusercontent.com/yichenchan/blogimg/master/img/dl_4.1_5.png" alt=""></p>
<p><img src="https://raw.githubusercontent.com/yichenchan/blogimg/master/img/dl_4.1_6.png" alt=""></p>
<p>中间的过滤器就是一个垂直边缘检测器，那么它是如何检测边缘的？</p>
<p><img src="https://raw.githubusercontent.com/yichenchan/blogimg/master/img/dl_4.1_7.png" alt=""></p>
<ul>
<li>边缘左侧像素值大，更明亮，右侧像素值小，更暗，最后得到的结果是更亮的区域在正中间，与检测出的垂直边缘相对应</li>
<li>检测出的边缘看起来很厚，是因为使用 6×6 的小图像，如果使用大图像就不会发生这种比例失调</li>
<li>过滤器告诉我们一个信息：某个垂直边缘是 3×3 的区域，左边有亮像素，右边有暗像素，而不在意中间有什么，这种区域被认为有垂直边缘</li>
</ul>
<h3 id="更多边缘检测例子"><a href="#更多边缘检测例子" class="headerlink" title="更多边缘检测例子"></a>更多边缘检测例子</h3><p>还有许多种精心设计的过滤器，比如水平边缘过滤器：</p>
<p><img src="https://raw.githubusercontent.com/yichenchan/blogimg/master/img/dl_4.1_8.png" alt=""></p>
<p>还有 sobel filter：</p>
<p><img src="https://raw.githubusercontent.com/yichenchan/blogimg/master/img/dl_4.1_9.png" alt=""></p>
<p>还有 scharr filter：</p>
<p><img src="https://raw.githubusercontent.com/yichenchan/blogimg/master/img/dl_4.1_10.png" alt=""></p>
<p>随着深度学习的发展我们发现，如果你想要检测一些复杂图片的边界，可能并不需要计算机视觉的研究人员挑选出这 9 个矩阵元素。你可以把矩阵里的这 9 个元素当做参数，通过反向传播来学习得到他们的数值，它能学到比前述这些人为定义的过滤器更加善于捕捉你的数据的统计学特征的过滤器。除了垂直和水平边界，同样能够学习去检测 45 度的边界 70 度 或 73 度，无论什么角度。</p>
<p><img src="https://raw.githubusercontent.com/yichenchan/blogimg/master/img/dl_4.1_11.png" alt=""></p>
<h3 id="填充-paddling"><a href="#填充-paddling" class="headerlink" title="填充 (paddling)"></a>填充 (paddling)</h3><h4 id="卷积运算的一些问题"><a href="#卷积运算的一些问题" class="headerlink" title="卷积运算的一些问题"></a>卷积运算的一些问题</h4><p>如果我们用 3×3 的过滤器去卷积 6×6 的图像，最后得到的是一个 4×4 的图像，这样会出现两个问题：</p>
<ul>
<li>输出的图像逐渐缩小，如果网络的层数很深，那么许多层之后会得到一个非常小的图片</li>
<li>角落上的像素值只会在输出中被使用一次，而中间的像素会重叠许多次，导致丢失了图片靠近边界上的信息</li>
</ul>
<h4 id="怎麽办"><a href="#怎麽办" class="headerlink" title="怎麽办"></a>怎麽办</h4><p>为了消除这两个问题，可以在卷积前用一个额外的边缘 (border) 填充图片，例如我们可以在 6×6 的图片边缘用一个 1 像素大小的额外边缘，那么这个图片就变成 8×8，和 3×3 的过滤器卷积之后得到一个 6×6 的图片，和原来尺寸一样，如下图所示。</p>
<p><img src="https://raw.githubusercontent.com/yichenchan/blogimg/master/img/dl_4.1_12.png" alt=""></p>
<ul>
<li>填充的边缘厚度为 p，上图中 p = 1</li>
</ul>
<h4 id="到底填充多少？——两种卷积"><a href="#到底填充多少？——两种卷积" class="headerlink" title="到底填充多少？——两种卷积"></a>到底填充多少？——两种卷积</h4><ol>
<li><p>valid 卷积 —— 没有填充</p>
<script type="math/tex; mode=display">
n \times n \quad * \quad f \times f \rightarrow (n-f+1) \times (n-f+1)\\
6 \times 6 \quad * \quad 3 \times 3 \rightarrow 4 \times 4</script></li>
<li><p>same 卷积 —— 填充后使得输入大小等于输出大小</p>
<script type="math/tex; mode=display">
(n+2p) \times (n+2p) \quad * \quad f \times f \rightarrow (n+2p-f+1) \times (n+2p-f+1)\\
\Rightarrow \ \ n+2p-f+1=n\\
\Rightarrow \ \ p=\frac{f-1}{2}</script><ul>
<li>其中 p 为填充的厚度，f 为过滤器的边长</li>
<li>当 f 为奇数时，p 按照上面公式取值即可以使得输入输出相同</li>
<li>一般实际中 f 都是使用奇数，有如下两个原因：<ul>
<li>如果 f 是偶数，则需要一些不对称填充</li>
<li>奇数过滤器可以有个中心点，称之为中心像素，可以描绘过滤器的位置</li>
</ul>
</li>
</ul>
</li>
</ol>
<h3 id="带步长的-strided-卷积"><a href="#带步长的-strided-卷积" class="headerlink" title="带步长的 (strided) 卷积"></a>带步长的 (strided) 卷积</h3><p>在卷积时过滤器移动的步长不为 1 称为带步长的卷积。如果步长 stride = 2 结果如下图所示。</p>
<p><img src="https://raw.githubusercontent.com/yichenchan/blogimg/master/img/dl_4.1_13.png" alt=""></p>
<p>加入我们有：</p>
<ul>
<li>n×n 的图像</li>
<li>f×f 的过滤器</li>
<li>填充 padding 为 p</li>
<li>步长 strides 为 s </li>
</ul>
<p>如果将两者卷积，输出为：</p>
<p><img src="https://raw.githubusercontent.com/yichenchan/blogimg/master/img/dl_4.1_14.png" alt=""></p>
<ul>
<li>其中 [ ] 为向下取整，也就是小于它的最大整数，[z] = floor(z)</li>
</ul>
<h3 id="一个提法的纠正"><a href="#一个提法的纠正" class="headerlink" title="一个提法的纠正"></a>一个提法的纠正</h3><p>实际上，在正式数学课本中，卷积操作前还需要一个额外的“翻转”操作，即将原来的过滤器先水平翻转再竖直翻转，如下图所示：</p>
<p><img src="https://raw.githubusercontent.com/yichenchan/blogimg/master/img/dl_4.1_15.png" alt=""></p>
<p>而深度学习中的“卷积”操作，将翻转操作取消了，数学上应该叫“交叉相关”，但是大多数深度学习文献都叫它卷积操作。</p>
<h3 id="对三维立方体的卷积"><a href="#对三维立方体的卷积" class="headerlink" title="对三维立方体的卷积"></a>对三维立方体的卷积</h3><p>假如我们的图像是 RGB 图像，那么它不是一个二维的灰度图像，而是一个 6×6×3 的三维图像，其中 3 为图像的<strong>通道数</strong>，这种图像如何卷积呢？</p>
<h4 id="单过滤器"><a href="#单过滤器" class="headerlink" title="单过滤器"></a>单过滤器</h4><p><img src="https://raw.githubusercontent.com/yichenchan/blogimg/master/img/dl_4.1_17.png" alt=""></p>
<ul>
<li>3 为图像的通道数，图像的通道数应该和过滤器的通道数一致</li>
<li>将每一层的过滤器的 9 个数字与对应通道的图像像素值相乘，最后把这所有的 27 个数字相加得到第一个输出，其他的以此类推</li>
</ul>
<h4 id="多过滤器"><a href="#多过滤器" class="headerlink" title="多过滤器"></a>多过滤器</h4><p>如果我们希望检测多个边缘，那么可以使用多个过滤器。</p>
<p><img src="https://raw.githubusercontent.com/yichenchan/blogimg/master/img/dl_4.1_18.png" alt=""></p>
<p>总结：</p>
<script type="math/tex; mode=display">
n \times n \times n_c \quad * \quad f \times f \times n_c \ \rightarrow (n-f+1) \times (n-f+1) \times n_c'</script><ul>
<li><p>其中 $n_c$ 为图像通道数，图像通道数应该和过滤器一致</p>
<ul>
<li>有时候 $n_c$ 称之为三维立方体的深度</li>
</ul>
</li>
<li><p>其中 $n_c’$ 为过滤器的数量，即检测的特征数量</p>
</li>
</ul>
<p>现在我们不仅可以直接处理拥有 3 个通道的 RGB 图片，而且更重要的是，可以检测两个特征，比如垂直、水平边缘，或者 10 个，128 个，甚至几百个不同的特征。</p>
<h2 id="单层卷积神经网络"><a href="#单层卷积神经网络" class="headerlink" title="单层卷积神经网络"></a>单层卷积神经网络</h2><h3 id="引例-1"><a href="#引例-1" class="headerlink" title="引例"></a>引例</h3><p>下面是一个卷积层的计算过程。</p>
<p><img src="https://raw.githubusercontent.com/yichenchan/blogimg/master/img/dl_4.1_20.png" alt=""></p>
<ul>
<li>假设输入图像为一个 6×6×3 的 $a^{[0]}$，那么输出为 4×4×2 的 $a^{[1]}$ </li>
<li>其中过滤器相当于参数 $w^{[1]}$，第二个蓝框里相当于 $z^{[1]}$，经过激活函数 Relu 之后变为 $a^{[1]}$</li>
</ul>
<h3 id="一层卷积层的参数"><a href="#一层卷积层的参数" class="headerlink" title="一层卷积层的参数"></a>一层卷积层的参数</h3><p>假设你有 10 个 3×3×3 的过滤器在一层神经网络中，那么这一层有多少个参数？</p>
<p>parameters = ( 3×3×3 +1 ) × 10 = 280 个</p>
<p>这是一个很好的特性：不管输入的图像有多大，比方 1000 x 1000 或者 5000 x 5000，这里的参数个数不变. 依然是 280 个。因此 用这 10 个过滤器来检测一个图片的不同的特征，比方垂直边缘线，水平边缘线或者其他不同的特征，不管图片多大，所用的参数个数都是一样的。</p>
<h3 id="标记符号总结"><a href="#标记符号总结" class="headerlink" title="标记符号总结"></a>标记符号总结</h3><p>如果第 $l$ 层是一个卷积层：</p>
<ul>
<li>过滤器尺寸：$f^{[l]}$</li>
<li>填充厚度：$p^{[l]}$</li>
<li>卷积步长：$s^{[l]}$</li>
<li>过滤器数量：$n_c^{[l]}$</li>
<li>输入：$n_H^{[l-1]} \times n_W^{[l-1]} \times n_c^{[l-1]}$ <ul>
<li>其中 H 代表高度，W 代表宽度，C 代表通道 channel</li>
</ul>
</li>
<li>输出：$n_H^{[l]} \times n_W^{[l]} \times n_c^{[l]}$ <ul>
<li>$n_H^{[l]}=[\frac{n_H^{[l-1]}+2p^{[l]}-f^{[l]}}{s^{[l]}}+1]$，$n_W^{[l]}=[\frac{n_W^{[l-1]}+2p^{[l]}-f^{[l]}}{s^{[l]}}+1]$ <ul>
<li>其中 $[ \ ]$ 为向下取整</li>
</ul>
</li>
</ul>
</li>
<li>每个过滤器为：$f^{[l]} \times f^{[l]} \times n_c^{[l-1]}$ (注意不是 $n_c^{[l]}$) </li>
<li>这一层的激活值：$a^{[l]} \rightarrow n_H^{[l]} \times n_W^{[l]} \times n_c^{[l]}$<ul>
<li>向量化激活值：$ A^{[l]} \rightarrow m \times n_H^{[l]} \times n_W^{[l]} \times n_c^{[l]}$ </li>
</ul>
</li>
<li>权重：$f^{[l]} \times f^{[l]} \times n_c^{[l-1]} \times n_c^{[l]}$<ul>
<li>其中 $n_c^{[l]}$ 为 $l$ 层的过滤器数量</li>
</ul>
</li>
<li>偏差：$1 \times 1 \times 1 \times n_c^{[l]}$ </li>
</ul>
<h2 id="深层卷积神经网络"><a href="#深层卷积神经网络" class="headerlink" title="深层卷积神经网络"></a>深层卷积神经网络</h2><h3 id="引例-2"><a href="#引例-2" class="headerlink" title="引例"></a>引例</h3><p><img src="https://raw.githubusercontent.com/yichenchan/blogimg/master/img/dl_4.1_21.png" alt=""></p>
<ul>
<li>最后我们得到一个 7×7×40 的激活值，一共 1960 个数展开为一个列向量，然后输入到一个逻辑回归或者 softmax 单元得到预测值</li>
</ul>
<h3 id="卷积网络中的层类型"><a href="#卷积网络中的层类型" class="headerlink" title="卷积网络中的层类型"></a>卷积网络中的层类型</h3><ul>
<li>卷积层 Convolution Layers (简称 Conv)</li>
<li>池化层 Pooling Layers (简称 Pool)</li>
<li>全连接层 Fully connected Layers (简称 FC)</li>
</ul>
<h3 id="池化层-Pooling-Layers"><a href="#池化层-Pooling-Layers" class="headerlink" title="池化层 (Pooling Layers)"></a>池化层 (Pooling Layers)</h3><ul>
<li><p>Max pooling 最大值采样</p>
<p><img src="https://raw.githubusercontent.com/yichenchan/blogimg/master/img/dl_4.1_22.png" alt=""></p>
<ul>
<li>Max pooling 和卷积操作基本一样，只是最后输出的是滤波器范围内的最大值</li>
<li>如果你把这个 4x4 的区域看作某个特征的集合，那么一个大的数字就意味着它或许检测到了一个特定的特征，所以左侧上方的四分之一区域有这样的特征，它或许是一个垂直的边沿 亦或一个更高或更弱，但是右侧上方的四分之一区域没有这个特征。所以 max pooling 做的是检测到所有地方的特征，四个特征中的一个被保留在 max pooling 的输出中。</li>
</ul>
</li>
<li><p>Average pooling 平均值采样</p>
<p><img src="https://raw.githubusercontent.com/yichenchan/blogimg/master/img/img/dl_4.1_23.png" alt=""></p>
<ul>
<li>平均值采样输出的是滤波器范围内所有值的平均值</li>
<li>不如 max pooling 常用</li>
</ul>
</li>
</ul>
<p>总结：</p>
<p><img src="https://raw.githubusercontent.com/yichenchan/blogimg/master/img/dl_4.1_24.png" alt=""></p>
<p>池化层没有任何参数要学习！是确定的函数！</p>
<h3 id="识别手写数字的例子"><a href="#识别手写数字的例子" class="headerlink" title="识别手写数字的例子"></a>识别手写数字的例子</h3><p>下面是一个用来识别手写数字的神经网络：</p>
<p><img src="https://raw.githubusercontent.com/yichenchan/blogimg/master/img/dl_4.1_25.png" alt=""></p>
<ul>
<li>conv 是 卷积层，pool 是池化层，FC 是全连接层</li>
<li>由于池化层没有权重和参数，所以不把它算作一个独立的层，而是视 conv1 和 pool1 为 layer 1，但是在某些文献中把卷积层和池化层视为两个独立的层</li>
</ul>
<p>总结：</p>
<p><img src="https://raw.githubusercontent.com/yichenchan/blogimg/master/img/dl_4.1_26.png" alt=""></p>
<ul>
<li>池化层没有参数</li>
<li>卷积层趋向于拥有越来越少的参数</li>
</ul>
<h2 id="为什么卷积如此有用"><a href="#为什么卷积如此有用" class="headerlink" title="为什么卷积如此有用"></a>为什么卷积如此有用</h2><ul>
<li>参数共享： 在特征检测器中（例如垂直边缘检测）对于图像的一部分是有用的，那么对于另一部分可能也是有用的。</li>
<li>连接的稀疏性：在每一层中，每个输出值只依靠一小部分输出值。也就是说每个输出值都只依赖于滤波器覆盖到的那几个数字，而剩下的像素值对它没有影响。</li>
</ul>
</div></article><div class="post-meta__tag-list"><a class="post-meta__tags" href="/tags/吴恩达深度学习笔记/">吴恩达深度学习笔记</a><a class="post-meta__tags" href="/tags/AI/">AI</a><a class="post-meta__tags" href="/tags/cnn/">cnn</a></div><div class="post-qr-code"><div class="post-qr-code-item"><img class="post-qr-code__img" src="/img/qr1.png"><div class="post-qr-code__desc">微信捐赠</div></div><div class="post-qr-code-item"><img class="post-qr-code__img" src="/img/qr2.jpg"><div class="post-qr-code__desc">支付宝捐赠</div></div></div><div class="social-share"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/social-share.js@1.0.16/dist/css/share.min.css"><script src="https://cdn.jsdelivr.net/npm/social-share.js@1.0.16/dist/js/social-share.min.js"></script><nav id="pagination"><div class="prev-post pull-left"><a href="/2018/10/16/吴恩达机器学习c4w1编程作业/"><i class="fa fa-chevron-left">  </i><span>coursera 吴恩达深度学习 Specialization 编程作业（course 4 week 1）</span></a></div><div class="next-post pull-right"><a href="/2018/09/26/坎坷选导师/"><span>坎坷开学路</span><i class="fa fa-chevron-right"></i></a></div></nav><div class="post-adv"><iframe frameborder="no" border="0" marginwidth="0" marginheight="0" width=530 height=86 src="//music.163.com/outchain/player?type=2&id=566993785&auto=1&height=66"></iframe></div><div id="lv-container" data-id="city" data-uid="MTAyMC8zODM1Mi8xNDg4MA=="><script>(function(d, s) {
    var j, e = d.getElementsByTagName(s)[0];
    if (typeof LivereTower === 'function') { return; }
    j = d.createElement(s);
    j.src = 'https://cdn-city.livere.com/js/embed.dist.js';
    j.async = true;
    e.parentNode.insertBefore(j, e);
})(document, 'script');</script></div></div></div><footer><div class="layout" id="footer"><div class="copyright">&copy;2018 - 2019 By 陈艺琛</div><div class="framework-info"><span>驱动 - </span><a href="http://hexo.io"><span>Hexo</span></a><span class="footer-separator">|</span><span>主题 - </span><a href="https://github.com/Molunerfinn/hexo-theme-melody"><span>Melody</span></a></div><div class="footer_custom_text">这里是我的一亩自耕田，记录自己的学习过程，生活随想和读书笔记，感谢您的参观！</div><div class="busuanzi"><script async src="https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script><span id="busuanzi_container_page_pv"><i class="fa fa-file-o"></i><span id="busuanzi_value_page_pv"></span><span></span></span></div></div></footer><i class="fa fa-arrow-up" id="go-up" aria-hidden="true"></i><script src="/js/third-party/anime.min.js"></script><script src="/js/third-party/jquery.min.js"></script><script src="/js/third-party/jquery.fancybox.min.js"></script><script src="/js/third-party/velocity.min.js"></script><script src="/js/third-party/velocity.ui.min.js"></script><script src="/js/utils.js?version=1.5.6"></script><script src="/js/fancybox.js?version=1.5.6"></script><script src="/js/sidebar.js?version=1.5.6"></script><script src="/js/copy.js?version=1.5.6"></script><script src="/js/fireworks.js?version=1.5.6"></script><script src="/js/transition.js?version=1.5.6"></script><script src="/js/scroll.js?version=1.5.6"></script><script src="/js/head.js?version=1.5.6"></script><script type="text/x-mathjax-config">MathJax.Hub.Config({
  tex2jax: {
    inlineMath: [ ['$','$'], ["\\(","\\)"]  ],
    processEscapes: true,
    skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
  },
  CommonHTML: {
    linebreaks: { automatic: true, width: "90% container" }
  },
  "HTML-CSS": { 
    linebreaks: { automatic: true, width: "90% container" }
  },
  "SVG": { 
    linebreaks: { automatic: true, width: "90% container" }
  }
});
</script><script type="text/x-mathjax-config">MathJax.Hub.Queue(function() {
  var all = MathJax.Hub.getAllJax(), i;
  for (i=0; i < all.length; i += 1) {
    all[i].SourceElement().parentNode.className += ' has-jax';
  }
});
</script><script src="https://cdn.bootcss.com/mathjax/2.7.2/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script><script src="/js/search/local-search.js"></script><div class="search-dialog" id="local-search"><div class="search-dialog__title" id="local-search-title">本地搜索</div><div id="local-input-panel"><div id="local-search-input"><div class="local-search-box"><input class="local-search-box--input" placeholder="搜索文章"></div></div></div><hr><div id="local-search-results"><div id="local-hits"></div><div id="local-stats"><div class="local-search-stats__hr" id="hr"><span>由</span> <a href="https://github.com/wzpan/hexo-generator-search" style="color:#49B1F5;">hexo-generator-search</a>
 <span>提供支持</span></div></div></div><span class="search-close-button"><i class="fa fa-times"></i></span></div><div class="search-mask"></div></body></html>