<!DOCTYPE html><html lang="zh-Hans"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"><meta name="description" content="coursera 吴恩达深度学习 Specialization 笔记（course 1 week 4）—— 深度神经网络"><meta name="keywords" content="吴恩达深度学习笔记,AI,神经网络"><meta name="author" content="陈艺琛,undefined"><meta name="copyright" content="陈艺琛"><title>coursera 吴恩达深度学习 Specialization 笔记（course 1 week 4）—— 深度神经网络 | 艺琛的 Livehouse</title><link rel="shortcut icon" href="/img/logo1.png"><link rel="stylesheet" href="/css/index.css?version=1.5.6"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/font-awesome@4.7.0/css/font-awesome.min.css?version=1.5.6"><link rel="dns-prefetch" href="https://cdn.staticfile.org"><link rel="dns-prefetch" href="https://cdn.bootcss.com"><link rel="dns-prefetch" href="https://creativecommons.org"><link rel="dns-prefetch" href="https://hm.baidu.com"><script>var _hmt = _hmt || [];
(function() {
  var hm = document.createElement("script");
  hm.src = "https://hm.baidu.com/hm.js?20c8efd323cd63b9f6bf846113eb6f60";
  var s = document.getElementsByTagName("script")[0]; 
  s.parentNode.insertBefore(hm, s);
})();</script><script>var GLOBAL_CONFIG = { 
  root: '/',
  algolia: undefined,
  localSearch: {"path":"search.xml","languages":{"hits_empty":"找不到您查询的内容:${query}"}},
  copy: {
    success: '复制成功',
    error: '复制错误',
    noSupport: '浏览器不支持'
  }
} </script></head><body><canvas class="fireworks"></canvas><i class="fa fa-arrow-right" id="toggle-sidebar" aria-hidden="true"></i><div id="sidebar"><div class="toggle-sidebar-info text-center"><span data-toggle="切换文章详情">切换站点概览</span><hr></div><div class="sidebar-toc"><div class="sidebar-toc__title">目录</div><div class="sidebar-toc__progress"><span class="progress-notice">你已经读了</span><span class="progress-num">0</span><span class="progress-percentage">%</span><div class="sidebar-toc__progress-bar"></div></div><div class="sidebar-toc__content"><ol class="toc"><li class="toc-item toc-level-2"><a class="toc-link" href="#深度神经网络概况"><span class="toc-number">1.</span> <span class="toc-text">深度神经网络概况</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#什么是深度神经网络"><span class="toc-number">1.1.</span> <span class="toc-text">什么是深度神经网络</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#神经网络的符号含义"><span class="toc-number">1.2.</span> <span class="toc-text">神经网络的符号含义</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#为什么我们需要“深度”"><span class="toc-number">1.3.</span> <span class="toc-text">为什么我们需要“深度”</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#例子1-——-面部识别"><span class="toc-number">1.3.1.</span> <span class="toc-text">例子1 —— 面部识别</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#例子2-——-电路理论"><span class="toc-number">1.3.2.</span> <span class="toc-text">例子2 —— 电路理论</span></a></li></ol></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#建立深度神经网络的基本框架"><span class="toc-number">2.</span> <span class="toc-text">建立深度神经网络的基本框架</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#框架的建立过程"><span class="toc-number">2.1.</span> <span class="toc-text">框架的建立过程</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#总体框架"><span class="toc-number">2.2.</span> <span class="toc-text">总体框架</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#前向传播"><span class="toc-number">3.</span> <span class="toc-text">前向传播</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#公式"><span class="toc-number">3.1.</span> <span class="toc-text">公式</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#维度的确定"><span class="toc-number">3.2.</span> <span class="toc-text">维度的确定</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#反向传播"><span class="toc-number">4.</span> <span class="toc-text">反向传播</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#公式-1"><span class="toc-number">4.1.</span> <span class="toc-text">公式</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#参数-parameters-与超参数-hyperparameters"><span class="toc-number">5.</span> <span class="toc-text">参数 (parameters) 与超参数 (hyperparameters)</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#定义"><span class="toc-number">5.1.</span> <span class="toc-text">定义</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#深度学习是一个基于试验的过程"><span class="toc-number">5.2.</span> <span class="toc-text">深度学习是一个基于试验的过程</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#深度学习和大脑有什么关系"><span class="toc-number">5.3.</span> <span class="toc-text">深度学习和大脑有什么关系</span></a></li></ol></li></ol></div></div><div class="author-info hide"><div class="author-info__avatar text-center"><img src="/img/avater.jpg"></div><div class="author-info__name text-center">陈艺琛</div><div class="author-info__description text-center">a student of HITsz————坚持滑板，热爱摇滚，偶尔弹吉他，喜欢阅读，抽空打游戏，在AI小白之路上踽踽独行。</div><div class="follow-button"><a href="https://web.okjike.com/user/9e0ec001-4bb6-4cab-af94-ea8b2f6067ef/post" target="_blank">在即刻上关注我</a></div><hr><div class="author-info-articles"><a class="author-info-articles__archives article-meta" href="/archives"><span class="pull-left">文章</span><span class="pull-right">17</span></a><a class="author-info-articles__tags article-meta" href="/tags"><span class="pull-left">标签</span><span class="pull-right">15</span></a><a class="author-info-articles__categories article-meta" href="/categories"><span class="pull-left">分类</span><span class="pull-right">3</span></a></div><hr><div class="author-info-links"><div class="author-info-links__title text-center">友链</div><a class="author-info-links__name text-center" href="https://www.liaoxuefeng.com" target="_blank">廖雪峰的博客</a><a class="author-info-links__name text-center" href="https://mooc.study.163.com/smartSpec/detail/1001319001.htm" target="_blank">网易机器学习公开课</a><a class="author-info-links__name text-center" href="https://developers.google.com/machine-learning/crash-course/?hl=zh-cn" target="_blank">谷歌机器学习速成</a><a class="author-info-links__name text-center" href="http://www.hitsz.edu.cn/index.html" target="_blank">哈工大深圳主页</a></div></div></div><div id="content-outer"><div id="top-container" style="background-image: url(https://raw.githubusercontent.com/yichenchan/blogimg/master/img/dl_topimg.png)"><div id="page-header"><span class="pull-left"> <a id="site-name" href="/">艺琛的 Livehouse</a></span><i class="fa fa-bars toggle-menu pull-right" aria-hidden="true"></i><span class="pull-right menus"><a class="site-page social-icon search"><i class="fa fa-search"></i><span> 搜索</span></a><a class="site-page" href="/">主页</a><a class="site-page" href="/categories/学习笔记">学习笔记</a><a class="site-page" href="/categories/读书观影笔记">读书观影笔记</a><a class="site-page" href="/categories/个人随想">个人随想</a><a class="site-page" href="/categories/爱好和生活">爱好和生活</a><a class="site-page" href="/gallery">相册</a><a class="site-page" href="/archives">所有博客</a><a class="site-page" href="/tags">特色标签</a><a class="site-page" href="/about">关于我</a></span></div><div id="post-info"><div id="post-title">coursera 吴恩达深度学习 Specialization 笔记（course 1 week 4）—— 深度神经网络</div><div id="post-meta"><time class="post-meta__date"><i class="fa fa-calendar" aria-hidden="true"></i> 2018-08-15</time><span class="post-meta__separator">|</span><i class="fa fa-inbox post-meta__icon" aria-hidden="true"></i><a class="post-meta__categories" href="/categories/学习笔记/">学习笔记</a></div></div></div><div class="layout" id="content-inner"><article id="post"><div class="article-container" id="post-content"><p>本周主要介绍<strong>深度神经网络</strong> (Deep Neural Networks)。</p>
<h2 id="深度神经网络概况"><a href="#深度神经网络概况" class="headerlink" title="深度神经网络概况"></a>深度神经网络概况</h2><h3 id="什么是深度神经网络"><a href="#什么是深度神经网络" class="headerlink" title="什么是深度神经网络"></a>什么是深度神经网络</h3><p><img src="https://raw.githubusercontent.com/yichenchan/blogimg/master/img/dl4.1.png" alt=""></p>
<p>所谓深浅取决于神经网络的层数，例如左上角的逻辑回归模型是一个“最浅的”神经网络，而右下角的神经网络具有五个隐藏层，可以算得上是深度神经网络。</p>
<a id="more"></a>
<h3 id="神经网络的符号含义"><a href="#神经网络的符号含义" class="headerlink" title="神经网络的符号含义"></a>神经网络的符号含义</h3><p><img src="https://raw.githubusercontent.com/yichenchan/blogimg/master/img/dl4.2.png" alt=""></p>
<ul>
<li><strong>l</strong> —— 表示神经网络的层数</li>
<li>$n^{[l]}$  表示 l 层的单元数，图中 $n^{[0]}=n_x=3,n^{[1]}=5,n^{[2]}=5,n^{[3]}=3,n^{[4]}=n^{[l]}=1$</li>
<li>$a^{[l]}=g^{[l]}(z^{[l]})$ 表示 l 层的激活向量</li>
<li>$W^{[l]}$ 表示产生 l 层的权重</li>
<li>$b^{[l]}$ 表示产生 l 层的偏差</li>
</ul>
<h3 id="为什么我们需要“深度”"><a href="#为什么我们需要“深度”" class="headerlink" title="为什么我们需要“深度”"></a>为什么我们需要“深度”</h3><h4 id="例子1-——-面部识别"><a href="#例子1-——-面部识别" class="headerlink" title="例子1 —— 面部识别"></a>例子1 —— 面部识别</h4><p><img src="https://raw.githubusercontent.com/yichenchan/blogimg/master/img/dl4.3.png" alt=""></p>
<p>神经网络的第一层可以被认为是一个边缘检测器，这一层的神经元正试图找到人脸的边缘在哪里，通过将像素分组的方法形成边缘，然后取消边缘检测，并将边缘组合在一起，形成面部的一部分，最后将面部的不同部位组合在一起我们可以识别不同的面部，我们可以将神经网络的浅层当作简单的检测函数，然后后一层将他们组合在一起，以便我们可以学习更复杂的功能</p>
<h4 id="例子2-——-电路理论"><a href="#例子2-——-电路理论" class="headerlink" title="例子2 —— 电路理论"></a>例子2 —— 电路理论</h4><p>用一个隐藏神经元数量较少但是具有深度的神经网络来计算某些函数时，如果我们尝试用浅层神经网络来计算同样的函数，则需要指数级的隐藏神经元来进行计算。</p>
<h2 id="建立深度神经网络的基本框架"><a href="#建立深度神经网络的基本框架" class="headerlink" title="建立深度神经网络的基本框架"></a>建立深度神经网络的基本框架</h2><h3 id="框架的建立过程"><a href="#框架的建立过程" class="headerlink" title="框架的建立过程"></a>框架的建立过程</h3><p><img src="https://raw.githubusercontent.com/yichenchan/blogimg/master/img/dl4.4.png" alt=""></p>
<p>假设方框中的隐藏层为第 l 层：</p>
<p>参数：$W^{[l]},b^{[l]}$</p>
<p>前向传播：输入 $a^{[l-1]}$ ，输出 $a^{[l]}$，缓存 $z^{[l]}$</p>
<p>反向传播：输入 $da^{[l]}$ 和缓存 $z^{[l]}$，输出 $da^{[l-1]}$，$dW^{[l]}$，$db^{[l]}$</p>
<p>画成框图如下所示：</p>
<p><img src="https://raw.githubusercontent.com/yichenchan/blogimg/master/img/dl4.5.png" alt=""></p>
<h3 id="总体框架"><a href="#总体框架" class="headerlink" title="总体框架"></a>总体框架</h3><p><img src="https://raw.githubusercontent.com/yichenchan/blogimg/master/img/dl4.6.png" alt=""></p>
<h2 id="前向传播"><a href="#前向传播" class="headerlink" title="前向传播"></a>前向传播</h2><h3 id="公式"><a href="#公式" class="headerlink" title="公式"></a>公式</h3><p>输入 $a^{[l-1]}$ ，输出 $a^{[l]}$，缓存 $z^{[l]}$</p>
<ol>
<li><p>非向量化</p>
<script type="math/tex; mode=display">
z^{[l]}=W^{[l]}a^{[a-1]}+b^{[l]}\\
a^{[l]}=g^{[l]}(z^{[l]})</script></li>
<li><p>向量化</p>
<script type="math/tex; mode=display">
Z^{[l]}=W^{[l]}A^{[a-1]}+b^{[l]}\\
A^{[l]}=g^{[l]}(Z^{[l]})</script></li>
</ol>
<blockquote>
<p>$X=A^{[0]} → A^{[1]}→A^{[2]}→…→ A^{[l]}$ </p>
</blockquote>
<h3 id="维度的确定"><a href="#维度的确定" class="headerlink" title="维度的确定"></a>维度的确定</h3><p>有如下的一个5层的神经网络：</p>
<p><img src="https://raw.githubusercontent.com/yichenchan/blogimg/master/img/dl4.7!.png" alt=""></p>
<p>对于单个训练样本：</p>
<p><img src="https://raw.githubusercontent.com/yichenchan/blogimg/master/img/dl4.8.png" alt=""></p>
<p>$z^{[l]},dz^{[l]},a^{[l]},da^{[l]}:(n^{[l]},1)\\W^{[l]},dW^{[l]}:(n^{[l]},n^{[l-1]})\\b^{[l]},db^{[l]}:(n^{[l]},1)$</p>
<p>对于多个训练样本：</p>
<p><img src="https://raw.githubusercontent.com/yichenchan/blogimg/master/img/dl4.9.png" alt=""></p>
<p>$ Z^{[l]},dZ^{[l]},A^{[l]},dA^{[l]}:(n^{[l]},m)\\W^{[l]},dW^{[l]}:(n^{[l]},n^{[l-1]})\\b^{[l]},db^{[l]}:(n^{[l]},1)$</p>
<blockquote>
<p>其中 $l=0$ 时，$A^{[0]}=X=(n^{[0]},m)$</p>
</blockquote>
<h2 id="反向传播"><a href="#反向传播" class="headerlink" title="反向传播"></a>反向传播</h2><h3 id="公式-1"><a href="#公式-1" class="headerlink" title="公式"></a>公式</h3><p>输入 $da^{[l]}$ 和缓存 $z^{[l]}$，输出 $da^{[l-1]}$，$dW^{[l]}$，$db^{[l]}$</p>
<ol>
<li><p>非向量化</p>
<script type="math/tex; mode=display">
dz^{[l]}=da^{[l]}*g^{[l]'}(z^{[l]})\\
dW^{[l]}=dz^{[l]}a^{[l-1]}\\
db^{[l]}=dz^{[l]}\\
da^{[l-1]}=W^{[l]T}dz^{[l]}\\
上式可得：da^{[l]}=W^{[l+1]T}dz^{[l+1]}\\
带入第一个式子可得：dz^{[l]}=W^{[l+1]T}dz^{[l+1]}*g^{[l]'}(z^{[l]})</script></li>
<li><p>向量化</p>
<script type="math/tex; mode=display">
dZ^{[l]}=dA^{[l]}*g^{[l]'}(Z^{[l]})\\
dW^{[l]}=\frac{1}{m}dZ^{[l]}A^{[l-1]T}\\
db^{[l]}=\frac{1}{m}np.sum(dZ^{[l]},axis=1,keepdims=True)\\
dA^{[l-1]}=W^{[l]T}dZ^{[l]}</script></li>
</ol>
<h2 id="参数-parameters-与超参数-hyperparameters"><a href="#参数-parameters-与超参数-hyperparameters" class="headerlink" title="参数 (parameters) 与超参数 (hyperparameters)"></a>参数 (parameters) 与超参数 (hyperparameters)</h2><h3 id="定义"><a href="#定义" class="headerlink" title="定义"></a>定义</h3><p>什么是参数：$W^{[1]},b^{[1]},W^{[2]},b^{[2]},W^{[3]},b^{[3]}…$ </p>
<p>什么是<strong>超参数</strong>：学习率 (learning rate) $\alpha$ ，迭代次数 (iterations)，隐藏层数 (hidden layers) L，隐藏单元数 (hidden units) $n^{[1]},n^{[2]}…$ ，激活函数 (activation function) 的选择，动量，最小批大小，各种形式的正则化参数等等，由于这些参数都会影响参数 W 和 b 的最终结果，所以我们称之为<strong>超参数</strong></p>
<h3 id="深度学习是一个基于试验的过程"><a href="#深度学习是一个基于试验的过程" class="headerlink" title="深度学习是一个基于试验的过程"></a>深度学习是一个基于试验的过程</h3><p><img src="https://raw.githubusercontent.com/yichenchan/blogimg/master/img/dl4.10.png" alt=""></p>
<h3 id="深度学习和大脑有什么关系"><a href="#深度学习和大脑有什么关系" class="headerlink" title="深度学习和大脑有什么关系"></a>深度学习和大脑有什么关系</h3><p>吴恩达：深度学习和大脑相似度并不高，但深度学习和大脑的确有某些可以对比的地方，如下图，但是人脑中的神经元是如何进行学习的还是一个迷，而且至今我们还不清楚到底人脑中有没有一个类似于反向传播或者梯度下降的算法</p>
<p><img src="https://raw.githubusercontent.com/yichenchan/blogimg/master/img/dl4.11.png" alt=""></p>
</div></article><div class="post-meta__tag-list"><a class="post-meta__tags" href="/tags/吴恩达深度学习笔记/">吴恩达深度学习笔记</a><a class="post-meta__tags" href="/tags/AI/">AI</a><a class="post-meta__tags" href="/tags/神经网络/">神经网络</a></div><div class="post-qr-code"><div class="post-qr-code-item"><img class="post-qr-code__img" src="/img/qr1.png"><div class="post-qr-code__desc">微信捐赠</div></div><div class="post-qr-code-item"><img class="post-qr-code__img" src="/img/qr2.jpg"><div class="post-qr-code__desc">支付宝捐赠</div></div></div><div class="social-share"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/social-share.js@1.0.16/dist/css/share.min.css"><script src="https://cdn.jsdelivr.net/npm/social-share.js@1.0.16/dist/js/social-share.min.js"></script><nav id="pagination"><div class="prev-post pull-left"><a href="/2018/08/27/吴恩达机器学习c1w4编程作业/"><i class="fa fa-chevron-left">  </i><span>coursera 吴恩达深度学习 Specialization 编程作业（course 1 week 4）</span></a></div><div class="next-post pull-right"><a href="/2018/08/14/吴恩达机器学习c1w3编程作业/"><span>coursera 吴恩达深度学习 Specialization 编程作业（course 1 week 3）</span><i class="fa fa-chevron-right"></i></a></div></nav><div class="post-adv"><iframe frameborder="no" border="0" marginwidth="0" marginheight="0" width=530 height=86 src="//music.163.com/outchain/player?type=2&id=566993785&auto=1&height=66"></iframe></div><div id="lv-container" data-id="city" data-uid="MTAyMC8zODM1Mi8xNDg4MA=="><script>(function(d, s) {
    var j, e = d.getElementsByTagName(s)[0];
    if (typeof LivereTower === 'function') { return; }
    j = d.createElement(s);
    j.src = 'https://cdn-city.livere.com/js/embed.dist.js';
    j.async = true;
    e.parentNode.insertBefore(j, e);
})(document, 'script');</script></div></div></div><footer><div class="layout" id="footer"><div class="copyright">&copy;2018 By 陈艺琛</div><div class="framework-info"><span>驱动 - </span><a href="http://hexo.io"><span>Hexo</span></a><span class="footer-separator">|</span><span>主题 - </span><a href="https://github.com/Molunerfinn/hexo-theme-melody"><span>Melody</span></a></div><div class="footer_custom_text">这里是我的一亩自耕田，记录自己的学习过程，生活随想和读书笔记，感谢您的参观！</div><div class="busuanzi"><script async src="//dn-lbstatics.qbox.me/busuanzi/2.3/busuanzi.pure.mini.js"></script><span id="busuanzi_container_page_pv"><i class="fa fa-file-o"></i><span id="busuanzi_value_page_pv"></span><span></span></span></div></div></footer><i class="fa fa-arrow-up" id="go-up" aria-hidden="true"></i><script src="/js/third-party/anime.min.js"></script><script src="/js/third-party/jquery.min.js"></script><script src="/js/third-party/jquery.fancybox.min.js"></script><script src="/js/third-party/velocity.min.js"></script><script src="/js/third-party/velocity.ui.min.js"></script><script src="/js/utils.js?version=1.5.6"></script><script src="/js/fancybox.js?version=1.5.6"></script><script src="/js/sidebar.js?version=1.5.6"></script><script src="/js/copy.js?version=1.5.6"></script><script src="/js/fireworks.js?version=1.5.6"></script><script src="/js/transition.js?version=1.5.6"></script><script src="/js/scroll.js?version=1.5.6"></script><script src="/js/head.js?version=1.5.6"></script><script type="text/x-mathjax-config">MathJax.Hub.Config({
  tex2jax: {
    inlineMath: [ ['$','$'], ["\\(","\\)"]  ],
    processEscapes: true,
    skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
  },
  CommonHTML: {
    linebreaks: { automatic: true, width: "90% container" }
  },
  "HTML-CSS": { 
    linebreaks: { automatic: true, width: "90% container" }
  },
  "SVG": { 
    linebreaks: { automatic: true, width: "90% container" }
  }
});
</script><script type="text/x-mathjax-config">MathJax.Hub.Queue(function() {
  var all = MathJax.Hub.getAllJax(), i;
  for (i=0; i < all.length; i += 1) {
    all[i].SourceElement().parentNode.className += ' has-jax';
  }
});
</script><script src="https://cdn.bootcss.com/mathjax/2.7.2/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script><script src="/js/search/local-search.js"></script><div class="search-dialog" id="local-search"><div class="search-dialog__title" id="local-search-title">本地搜索</div><div id="local-input-panel"><div id="local-search-input"><div class="local-search-box"><input class="local-search-box--input" placeholder="搜索文章"></div></div></div><hr><div id="local-search-results"><div id="local-hits"></div><div id="local-stats"><div class="local-search-stats__hr" id="hr"><span>由</span> <a href="https://github.com/wzpan/hexo-generator-search" style="color:#49B1F5;">hexo-generator-search</a>
 <span>提供支持</span></div></div></div><span class="search-close-button"><i class="fa fa-times"></i></span></div><div class="search-mask"></div></body></html>