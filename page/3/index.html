<!DOCTYPE html><html lang="zh-Hans"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"><meta name="description" content="a student of HITsz————坚持滑板，热爱摇滚，偶尔弹吉他，喜欢阅读，抽空打游戏，在AI小白之路上踽踽独行。"><meta name="keywords" content=""><meta name="author" content="陈艺琛,undefined"><meta name="copyright" content="陈艺琛"><title>chenyichen's blog | 在AI小白之路上踽踽独行 | 艺琛的 Livehouse</title><link rel="shortcut icon" href="/img/logo1.png"><link rel="stylesheet" href="/css/index.css?version=1.5.6"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/font-awesome@4.7.0/css/font-awesome.min.css?version=1.5.6"><link rel="dns-prefetch" href="https://cdn.staticfile.org"><link rel="dns-prefetch" href="https://cdn.bootcss.com"><link rel="dns-prefetch" href="https://creativecommons.org"><link rel="dns-prefetch" href="https://hm.baidu.com"><script>var _hmt = _hmt || [];
(function() {
  var hm = document.createElement("script");
  hm.src = "https://hm.baidu.com/hm.js?20c8efd323cd63b9f6bf846113eb6f60";
  var s = document.getElementsByTagName("script")[0]; 
  s.parentNode.insertBefore(hm, s);
})();</script><script>var GLOBAL_CONFIG = { 
  root: '/',
  algolia: undefined,
  localSearch: {"path":"search.xml","languages":{"hits_empty":"找不到您查询的内容:${query}"}},
  copy: {
    success: '复制成功',
    error: '复制错误',
    noSupport: '浏览器不支持'
  }
} </script></head><body><canvas class="fireworks"></canvas><i class="fa fa-arrow-right" id="toggle-sidebar" aria-hidden="true"></i><div id="sidebar"><div class="author-info"><div class="author-info__avatar text-center"><img src="/img/avater.jpg"></div><div class="author-info__name text-center">陈艺琛</div><div class="author-info__description text-center">a student of HITsz————坚持滑板，热爱摇滚，偶尔弹吉他，喜欢阅读，抽空打游戏，在AI小白之路上踽踽独行。</div><div class="follow-button"><a href="https://web.okjike.com/user/9e0ec001-4bb6-4cab-af94-ea8b2f6067ef/post" target="_blank">在即刻上关注我</a></div><hr><div class="author-info-articles"><a class="author-info-articles__archives article-meta" href="/archives"><span class="pull-left">文章</span><span class="pull-right">33</span></a><a class="author-info-articles__tags article-meta" href="/tags"><span class="pull-left">标签</span><span class="pull-right">27</span></a><a class="author-info-articles__categories article-meta" href="/categories"><span class="pull-left">分类</span><span class="pull-right">3</span></a></div><hr><div class="author-info-links"><div class="author-info-links__title text-center">友链</div><a class="author-info-links__name text-center" href="https://www.liaoxuefeng.com" target="_blank">廖雪峰的博客</a><a class="author-info-links__name text-center" href="https://mooc.study.163.com/smartSpec/detail/1001319001.htm" target="_blank">网易机器学习公开课</a><a class="author-info-links__name text-center" href="https://developers.google.com/machine-learning/crash-course/?hl=zh-cn" target="_blank">谷歌机器学习速成</a><a class="author-info-links__name text-center" href="http://www.hitsz.edu.cn/index.html" target="_blank">哈工大深圳主页</a></div></div></div><nav id="nav" style="background-image: url(https://raw.githubusercontent.com/yichenchan/blogimg/master/img/skater11.jpg)"><div id="page-header"><span class="pull-left"> <a id="site-name" href="/">艺琛的 Livehouse</a></span><i class="fa fa-bars toggle-menu pull-right" aria-hidden="true"></i><span class="pull-right menus"><a class="site-page social-icon search"><i class="fa fa-search"></i><span> 搜索</span></a><a class="site-page" href="/">主页</a><a class="site-page" href="/categories/学习笔记">学习笔记</a><a class="site-page" href="/categories/读书观影笔记">读书观影笔记</a><a class="site-page" href="/categories/个人随想">个人随想</a><a class="site-page" href="/categories/爱好和生活">爱好和生活</a><a class="site-page" href="/gallery">相册</a><a class="site-page" href="/archives">所有博客</a><a class="site-page" href="/tags">特色标签</a><a class="site-page" href="/about">关于我</a></span></div><div id="site-info"><div id="site-title">艺琛的 Livehouse</div><div id="site-sub-title">chenyichen's blog | 在AI小白之路上踽踽独行</div><div id="site-social-icons"><a class="social-icon" href="https://github.com/yichenchan" target="_blank"><i class="fa fa-github"></i></a><a class="social-icon" href="https://weibo.com/5101047894/profile?rightmod=1&amp;wvr=6&amp;mod=personinfo" target="_blank"><i class="fa fa-weibo"></i></a><a class="social-icon" href="c840098794@gmail.com" target="_blank"><i class="fa fa-email"></i></a><a class="social-icon" href="https://steamcommunity.com/id/840098794/" target="_blank"><i class="fa fa-steam"></i></a><a class="social-icon search"><i class="fa fa-search"></i></a></div></div></nav><div id="content-outer"><div class="layout" id="content-inner"><div class="recent-post-item article-container"><a class="article-title" href="/2018/09/02/吴恩达机器学习笔记c2w2/">coursera 吴恩达深度学习 Specialization 笔记（course 2 week 2）—— 优化算法的改进</a><time class="post-meta__date"><i class="fa fa-calendar" aria-hidden="true"></i> 2018-09-02</time><span class="article-meta"><span class="article-meta__separator">|</span><i class="fa fa-inbox article-meta__icon" aria-hidden="true"></i><a class="article-meta__categories" href="/categories/学习笔记/">学习笔记</a></span><span class="article-meta tags"><span class="article-meta__separator">|</span><i class="fa fa-tag article-meta__icon" aria-hidden="true"></i><a class="article-meta__tags" href="/tags/吴恩达深度学习笔记/">吴恩达深度学习笔记</a><span class="article-meta__link">-</span><i class="fa fa-tag article-meta__icon" aria-hidden="true"></i><a class="article-meta__tags" href="/tags/AI/">AI</a><span class="article-meta__link">-</span><i class="fa fa-tag article-meta__icon" aria-hidden="true"></i><a class="article-meta__tags" href="/tags/神经网络优化/">神经网络优化</a><span class="article-meta__link">-</span><i class="fa fa-tag article-meta__icon" aria-hidden="true"></i><a class="article-meta__tags" href="/tags/优化算法/">优化算法</a></span><div class="content"><p>本周主要学习不同的参数优化方式，提高模型的训练速度。</p>
<h2 id="小批量梯度下降算法-mini-batch-gradient-descent"><a href="#小批量梯度下降算法-mini-batch-gradient-descent" class="headerlink" title="小批量梯度下降算法 (mini-batch gradient descent)"></a>小批量梯度下降算法 (mini-batch gradient descent)</h2><h3 id="算法介绍"><a href="#算法介绍" class="headerlink" title="算法介绍"></a>算法介绍</h3><p>向量化可以有效率地同时计算 m 个样本，但是当样本数为几百万时，速度依然会很慢，每一次迭代都必须先处理几百万的数据集才能往前一步，所以我们可以使用这个算法进行加速。</p>
<p>首先我们将训练集划分为一个一个微小的训练集，也就是小批量训练集 (mini-batch)，比如每一个微小训练集只有 1000 个样本：</p>
<p><img src="https://raw.githubusercontent.com/yichenchan/blogimg/master/img/dl_code_2.2_2.png" alt=""></p></div><a class="more" href="/2018/09/02/吴恩达机器学习笔记c2w2/#more">阅读更多</a><hr></div><div class="recent-post-item article-container"><a class="article-title" href="/2018/09/01/beck观后感/">《Beck》观后感</a><time class="post-meta__date"><i class="fa fa-calendar" aria-hidden="true"></i> 2018-09-01</time><span class="article-meta"><span class="article-meta__separator">|</span><i class="fa fa-inbox article-meta__icon" aria-hidden="true"></i><a class="article-meta__categories" href="/categories/读书观影笔记/">读书观影笔记</a></span><span class="article-meta tags"><span class="article-meta__separator">|</span><i class="fa fa-tag article-meta__icon" aria-hidden="true"></i><a class="article-meta__tags" href="/tags/摇滚/">摇滚</a><span class="article-meta__link">-</span><i class="fa fa-tag article-meta__icon" aria-hidden="true"></i><a class="article-meta__tags" href="/tags/音乐/">音乐</a></span><div class="content"><p>　　我终于找到我的本命番了，它的名字叫《Beck》，为啥我知道这是本命番呢，因为这是第一部我看到最后迟迟舍不得看完的番，一共２６集，每天睡前看几集，看了有十几天，不敢一次看完，因为看完了我的梦就碎了，是的，这是一个追梦的故事，我相信任何热爱摇滚，热爱音乐，热爱吉他，渴望或者已经开始玩乐队的人，都会对这部番有着深深的感动和发自内心的共鸣。因为这部番，我拿起了好久没碰的木琴，并开始挑选我的第一把电吉他……</p>
<p><img src="https://raw.githubusercontent.com/yichenchan/blogimg/master/img/beck%E8%A7%82%E5%90%8E%E6%84%9F_topimg.jpg" alt=""></p></div><a class="more" href="/2018/09/01/beck观后感/#more">阅读更多</a><hr></div><div class="recent-post-item article-container"><a class="article-title" href="/2018/09/01/吴恩达机器学习c2w1编程作业/">coursera 吴恩达深度学习 Specialization 编程作业（course 2 week 1）</a><time class="post-meta__date"><i class="fa fa-calendar" aria-hidden="true"></i> 2018-09-01</time><span class="article-meta"><span class="article-meta__separator">|</span><i class="fa fa-inbox article-meta__icon" aria-hidden="true"></i><a class="article-meta__categories" href="/categories/学习笔记/">学习笔记</a></span><span class="article-meta tags"><span class="article-meta__separator">|</span><i class="fa fa-tag article-meta__icon" aria-hidden="true"></i><a class="article-meta__tags" href="/tags/吴恩达深度学习笔记/">吴恩达深度学习笔记</a><span class="article-meta__link">-</span><i class="fa fa-tag article-meta__icon" aria-hidden="true"></i><a class="article-meta__tags" href="/tags/AI/">AI</a><span class="article-meta__link">-</span><i class="fa fa-tag article-meta__icon" aria-hidden="true"></i><a class="article-meta__tags" href="/tags/神经网络优化/">神经网络优化</a><span class="article-meta__link">-</span><i class="fa fa-tag article-meta__icon" aria-hidden="true"></i><a class="article-meta__tags" href="/tags/正则化/">正则化</a><span class="article-meta__link">-</span><i class="fa fa-tag article-meta__icon" aria-hidden="true"></i><a class="article-meta__tags" href="/tags/初始化/">初始化</a></span><div class="content"><h2 id="初始化"><a href="#初始化" class="headerlink" title="初始化"></a>初始化</h2><p>这次编程作业对比了三种不同的初始化方法的不同，三种方法分别是“零初始化”、“随机初始化”、“He 初始化”。</p>
<p>这是所用的数据，我们要将红点和蓝点分类：</p>
<p><img src="https://raw.githubusercontent.com/yichenchan/blogimg/master/img/dl_code_2.1_1.png" alt=""></p></div><a class="more" href="/2018/09/01/吴恩达机器学习c2w1编程作业/#more">阅读更多</a><hr></div><div class="recent-post-item article-container"><a class="article-title" href="/2018/08/29/吴恩达机器学习笔记c2w1/">coursera 吴恩达深度学习 Specialization 笔记（course 2 week 1）—— 正则化等</a><time class="post-meta__date"><i class="fa fa-calendar" aria-hidden="true"></i> 2018-08-29</time><span class="article-meta"><span class="article-meta__separator">|</span><i class="fa fa-inbox article-meta__icon" aria-hidden="true"></i><a class="article-meta__categories" href="/categories/学习笔记/">学习笔记</a></span><span class="article-meta tags"><span class="article-meta__separator">|</span><i class="fa fa-tag article-meta__icon" aria-hidden="true"></i><a class="article-meta__tags" href="/tags/吴恩达深度学习笔记/">吴恩达深度学习笔记</a><span class="article-meta__link">-</span><i class="fa fa-tag article-meta__icon" aria-hidden="true"></i><a class="article-meta__tags" href="/tags/AI/">AI</a><span class="article-meta__link">-</span><i class="fa fa-tag article-meta__icon" aria-hidden="true"></i><a class="article-meta__tags" href="/tags/神经网络优化/">神经网络优化</a><span class="article-meta__link">-</span><i class="fa fa-tag article-meta__icon" aria-hidden="true"></i><a class="article-meta__tags" href="/tags/正则化/">正则化</a><span class="article-meta__link">-</span><i class="fa fa-tag article-meta__icon" aria-hidden="true"></i><a class="article-meta__tags" href="/tags/初始化/">初始化</a></span><div class="content"><p>deeplearning.ai 的第二个课程名为 <strong>改进深度神经网络：超参数调整，正则化和优化 (Improving Deep Neural Networks: Hyperparameter tuning, Regularization and Optimization)</strong> ，这门课程教你使深度学习表现更好的“魔法”，而不是把神经网络当作一个黑箱，你会理解什么使得神经网络表现更好，而且能更系统地得到好的结果，你还会学到一些 tensorflow 知识。通过三周的学习，你将能够：</p>
<ul>
<li>了解构建深度学习应用程序的行业最佳实践</li>
<li>能够有效地使用常见的神经网络技巧，包括初始化，L2 正则化和丢失正则化，批量归一化，梯度检查</li>
<li>能够实现和应用各种优化算法，例如小批量梯度下降，动量，PMSprop 和 Adam，并检查它们的收敛性</li>
<li>了解如何设置训练/开发/测试集和分析偏差/方差</li>
<li>能够在 TensorFlow 上实现神经网络</li>
</ul></div><a class="more" href="/2018/08/29/吴恩达机器学习笔记c2w1/#more">阅读更多</a><hr></div><div class="recent-post-item article-container"><a class="article-title" href="/2018/08/27/吴恩达机器学习c1w4编程作业/">coursera 吴恩达深度学习 Specialization 编程作业（course 1 week 4）</a><time class="post-meta__date"><i class="fa fa-calendar" aria-hidden="true"></i> 2018-08-27</time><span class="article-meta"><span class="article-meta__separator">|</span><i class="fa fa-inbox article-meta__icon" aria-hidden="true"></i><a class="article-meta__categories" href="/categories/学习笔记/">学习笔记</a></span><span class="article-meta tags"><span class="article-meta__separator">|</span><i class="fa fa-tag article-meta__icon" aria-hidden="true"></i><a class="article-meta__tags" href="/tags/吴恩达深度学习笔记/">吴恩达深度学习笔记</a><span class="article-meta__link">-</span><i class="fa fa-tag article-meta__icon" aria-hidden="true"></i><a class="article-meta__tags" href="/tags/AI/">AI</a><span class="article-meta__link">-</span><i class="fa fa-tag article-meta__icon" aria-hidden="true"></i><a class="article-meta__tags" href="/tags/神经网络/">神经网络</a></span><div class="content"><h1 id="第一部分：基本架构"><a href="#第一部分：基本架构" class="headerlink" title="第一部分：基本架构"></a>第一部分：基本架构</h1><p>这是深度学习专项课程第一课第四周的编程作业的第一部分，通过这一部分，可以学到：</p>
<ul>
<li>使用非线性单元比如 ReLU 来提高模型</li>
<li>建立一个更深的神经网络（大于一个隐藏层）</li>
<li>实现一个易用的神经网络类</li>
</ul>
<h2 id="包的引入"><a href="#包的引入" class="headerlink" title="包的引入"></a>包的引入</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 包的引入</span></span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> h5py </span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">from</span> testCases_v4 <span class="keyword">import</span> *</span><br><span class="line"><span class="keyword">from</span> dnn_utils_v2 <span class="keyword">import</span> sigmoid, sigmoid_backward, relu, relu_backward</span><br><span class="line"></span><br><span class="line">%matplotlib inline <span class="comment"># %符号为ipython的魔法函数，与画图有关，在pycharm中会报错</span></span><br><span class="line">plt.rcParams[<span class="string">'figure.figsize'</span>] = (<span class="number">5.0</span>, <span class="number">4.0</span>) <span class="comment"># set default size of plots</span></span><br><span class="line">plt.rcParams[<span class="string">'image.interpolation'</span>] = <span class="string">'nearest'</span></span><br><span class="line">plt.rcParams[<span class="string">'image.cmap'</span>] = <span class="string">'gray'</span></span><br><span class="line"></span><br><span class="line">%load_ext autoreload</span><br><span class="line">%autoreload <span class="number">2</span></span><br></pre></td></tr></table></figure></div><a class="more" href="/2018/08/27/吴恩达机器学习c1w4编程作业/#more">阅读更多</a><hr></div><div class="recent-post-item article-container"><a class="article-title" href="/2018/08/15/吴恩达机器学习笔记c1w4/">coursera 吴恩达深度学习 Specialization 笔记（course 1 week 4）—— 深度神经网络</a><time class="post-meta__date"><i class="fa fa-calendar" aria-hidden="true"></i> 2018-08-15</time><span class="article-meta"><span class="article-meta__separator">|</span><i class="fa fa-inbox article-meta__icon" aria-hidden="true"></i><a class="article-meta__categories" href="/categories/学习笔记/">学习笔记</a></span><span class="article-meta tags"><span class="article-meta__separator">|</span><i class="fa fa-tag article-meta__icon" aria-hidden="true"></i><a class="article-meta__tags" href="/tags/吴恩达深度学习笔记/">吴恩达深度学习笔记</a><span class="article-meta__link">-</span><i class="fa fa-tag article-meta__icon" aria-hidden="true"></i><a class="article-meta__tags" href="/tags/AI/">AI</a><span class="article-meta__link">-</span><i class="fa fa-tag article-meta__icon" aria-hidden="true"></i><a class="article-meta__tags" href="/tags/神经网络/">神经网络</a></span><div class="content"><p>本周主要介绍<strong>深度神经网络</strong> (Deep Neural Networks)。</p>
<h2 id="深度神经网络概况"><a href="#深度神经网络概况" class="headerlink" title="深度神经网络概况"></a>深度神经网络概况</h2><h3 id="什么是深度神经网络"><a href="#什么是深度神经网络" class="headerlink" title="什么是深度神经网络"></a>什么是深度神经网络</h3><p><img src="https://raw.githubusercontent.com/yichenchan/blogimg/master/img/dl4.1.png" alt=""></p>
<p>所谓深浅取决于神经网络的层数，例如左上角的逻辑回归模型是一个“最浅的”神经网络，而右下角的神经网络具有五个隐藏层，可以算得上是深度神经网络。</p></div><a class="more" href="/2018/08/15/吴恩达机器学习笔记c1w4/#more">阅读更多</a><hr></div><div class="recent-post-item article-container"><a class="article-title" href="/2018/08/14/吴恩达机器学习c1w3编程作业/">coursera 吴恩达深度学习 Specialization 编程作业（course 1 week 3）</a><time class="post-meta__date"><i class="fa fa-calendar" aria-hidden="true"></i> 2018-08-14</time><span class="article-meta"><span class="article-meta__separator">|</span><i class="fa fa-inbox article-meta__icon" aria-hidden="true"></i><a class="article-meta__categories" href="/categories/学习笔记/">学习笔记</a></span><span class="article-meta tags"><span class="article-meta__separator">|</span><i class="fa fa-tag article-meta__icon" aria-hidden="true"></i><a class="article-meta__tags" href="/tags/吴恩达深度学习笔记/">吴恩达深度学习笔记</a><span class="article-meta__link">-</span><i class="fa fa-tag article-meta__icon" aria-hidden="true"></i><a class="article-meta__tags" href="/tags/AI/">AI</a><span class="article-meta__link">-</span><i class="fa fa-tag article-meta__icon" aria-hidden="true"></i><a class="article-meta__tags" href="/tags/神经网络/">神经网络</a></span><div class="content"><p>这是深度学习专项课程第一课第三周的编程作业，通过这次编程作业，可以学到：</p>
<ul>
<li>用一个单隐层神经网络实现一个二元分类器</li>
<li>使用非线性的激活函数</li>
<li>计算交叉熵损失</li>
<li>实现前向和后向传播</li>
</ul>
<h2 id="包的引入"><a href="#包的引入" class="headerlink" title="包的引入"></a>包的引入</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 引入包</span></span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np </span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt <span class="comment"># 画图</span></span><br><span class="line"><span class="keyword">from</span> testCases_v2 <span class="keyword">import</span> * <span class="comment"># 提供测试例子评估函数正确性</span></span><br><span class="line"><span class="keyword">import</span> sklearn <span class="comment"># 提供简单有效的数据挖掘和数据分析工具</span></span><br><span class="line"><span class="keyword">import</span> sklearn.datasets</span><br><span class="line"><span class="keyword">import</span> sklearn.linear_model</span><br><span class="line"><span class="keyword">from</span> planar_utils <span class="keyword">import</span> plot_decision_boundary, sigmoid, load_planar_dataset, load_extra_datasets <span class="comment"># 提供一些有用的函数</span></span><br><span class="line"></span><br><span class="line">%matplotlib.inline</span><br><span class="line"></span><br><span class="line">np.random.seed(<span class="number">1</span>) <span class="comment"># 使得每次生成的随机数都和第一次相同</span></span><br></pre></td></tr></table></figure></div><a class="more" href="/2018/08/14/吴恩达机器学习c1w3编程作业/#more">阅读更多</a><hr></div><div class="recent-post-item article-container"><a class="article-title" href="/2018/08/11/吴恩达机器学习笔记c1w3/">coursera 吴恩达深度学习 Specialization 笔记（course 1 week 3）—— 浅层神经网络</a><time class="post-meta__date"><i class="fa fa-calendar" aria-hidden="true"></i> 2018-08-11</time><span class="article-meta"><span class="article-meta__separator">|</span><i class="fa fa-inbox article-meta__icon" aria-hidden="true"></i><a class="article-meta__categories" href="/categories/学习笔记/">学习笔记</a></span><span class="article-meta tags"><span class="article-meta__separator">|</span><i class="fa fa-tag article-meta__icon" aria-hidden="true"></i><a class="article-meta__tags" href="/tags/吴恩达深度学习笔记/">吴恩达深度学习笔记</a><span class="article-meta__link">-</span><i class="fa fa-tag article-meta__icon" aria-hidden="true"></i><a class="article-meta__tags" href="/tags/AI/">AI</a><span class="article-meta__link">-</span><i class="fa fa-tag article-meta__icon" aria-hidden="true"></i><a class="article-meta__tags" href="/tags/神经网络/">神经网络</a></span><div class="content"><p>本周主要介绍<strong>单隐层神经网络</strong> (one hidden layer Neural Network)。</p>
<h2 id="神经网络概况"><a href="#神经网络概况" class="headerlink" title="神经网络概况"></a>神经网络概况</h2><h3 id="什么是神经网络"><a href="#什么是神经网络" class="headerlink" title="什么是神经网络"></a>什么是神经网络</h3><p>逻辑回归的计算图如下，这是一个最小的神经网络：</p>
<p><img src="https://raw.githubusercontent.com/yichenchan/blogimg/master/img/dl3.2.png" alt=""></p>
<p><img src="https://raw.githubusercontent.com/yichenchan/blogimg/master/img/dl3.1.png" alt=""></p>
<p>堆叠一系列的 $\sigma$ 单元，构建一个单隐层神经网络：</p></div><a class="more" href="/2018/08/11/吴恩达机器学习笔记c1w3/#more">阅读更多</a><hr></div><div class="recent-post-item article-container"><a class="article-title" href="/2018/08/09/吴恩达机器学习c1w2编程作业/">coursera 吴恩达深度学习 Specialization 编程作业（course 1 week 2）</a><time class="post-meta__date"><i class="fa fa-calendar" aria-hidden="true"></i> 2018-08-09</time><span class="article-meta"><span class="article-meta__separator">|</span><i class="fa fa-inbox article-meta__icon" aria-hidden="true"></i><a class="article-meta__categories" href="/categories/学习笔记/">学习笔记</a></span><span class="article-meta tags"><span class="article-meta__separator">|</span><i class="fa fa-tag article-meta__icon" aria-hidden="true"></i><a class="article-meta__tags" href="/tags/吴恩达深度学习笔记/">吴恩达深度学习笔记</a><span class="article-meta__link">-</span><i class="fa fa-tag article-meta__icon" aria-hidden="true"></i><a class="article-meta__tags" href="/tags/AI/">AI</a><span class="article-meta__link">-</span><i class="fa fa-tag article-meta__icon" aria-hidden="true"></i><a class="article-meta__tags" href="/tags/神经网络/">神经网络</a><span class="article-meta__link">-</span><i class="fa fa-tag article-meta__icon" aria-hidden="true"></i><a class="article-meta__tags" href="/tags/逻辑回归/">逻辑回归</a><span class="article-meta__link">-</span><i class="fa fa-tag article-meta__icon" aria-hidden="true"></i><a class="article-meta__tags" href="/tags/numpy/">numpy</a></span><div class="content"><h2 id="numpy-使用基础"><a href="#numpy-使用基础" class="headerlink" title="numpy 使用基础"></a>numpy 使用基础</h2><p>Numpy 是 Python 里用于科学计算的模块，由一个<a href="www.numpy.org">开源社区</a>进行维护，下面介绍一些用于神经网络搭建的函数的构建</p>
<h3 id="sigmoid-函数，np-exp"><a href="#sigmoid-函数，np-exp" class="headerlink" title="sigmoid 函数，np.exp( )"></a>sigmoid 函数，np.exp( )</h3><p>回忆：$sigmoid(x)=\frac {1}{1+e^{-x}}$</p>
<p>如果 $ x = (x_1, x_2, …, x_n)$ 是一个行向量，那么 $np.exp(x)$ 会将 $exp( )$ 函数用于 x 的每个元素，输出 $np.exp(x) = (e^{x_1}, e^{x_2}, …, e^{x_n})$</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line"><span class="comment"># np.exp的例子</span></span><br><span class="line">x = np.array([<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>])<span class="comment">#x 为一个行向量</span></span><br><span class="line">print(np.exp(x)) <span class="comment"># 结果为 (exp(1), exp(2), exp(3))</span></span><br></pre></td></tr></table></figure>
<p>>> [  2.71828183   7.3890561   20.08553692]</p></div><a class="more" href="/2018/08/09/吴恩达机器学习c1w2编程作业/#more">阅读更多</a><hr></div><div class="recent-post-item article-container"><a class="article-title" href="/2018/08/07/吴恩达机器学习笔记c1w2/">coursera 吴恩达深度学习 Specialization 笔记（course 1 week 2）—— 神经网络基础</a><time class="post-meta__date"><i class="fa fa-calendar" aria-hidden="true"></i> 2018-08-07</time><span class="article-meta"><span class="article-meta__separator">|</span><i class="fa fa-inbox article-meta__icon" aria-hidden="true"></i><a class="article-meta__categories" href="/categories/学习笔记/">学习笔记</a></span><span class="article-meta tags"><span class="article-meta__separator">|</span><i class="fa fa-tag article-meta__icon" aria-hidden="true"></i><a class="article-meta__tags" href="/tags/吴恩达深度学习笔记/">吴恩达深度学习笔记</a><span class="article-meta__link">-</span><i class="fa fa-tag article-meta__icon" aria-hidden="true"></i><a class="article-meta__tags" href="/tags/AI/">AI</a><span class="article-meta__link">-</span><i class="fa fa-tag article-meta__icon" aria-hidden="true"></i><a class="article-meta__tags" href="/tags/神经网络/">神经网络</a><span class="article-meta__link">-</span><i class="fa fa-tag article-meta__icon" aria-hidden="true"></i><a class="article-meta__tags" href="/tags/逻辑回归/">逻辑回归</a></span><div class="content"><p>本周主要介绍<strong>逻辑回归</strong>算法 (Logistics Regression)。</p>
<h2 id="二元分类"><a href="#二元分类" class="headerlink" title="二元分类"></a>二元分类</h2><h3 id="定义"><a href="#定义" class="headerlink" title="定义"></a>定义</h3><p>输出值为离散的两个值，即 1 或者 0</p>
<h3 id="例子——判断图片是（1）不是（0）猫"><a href="#例子——判断图片是（1）不是（0）猫" class="headerlink" title="例子——判断图片是（1）不是（0）猫"></a>例子——判断图片是（1）不是（0）猫</h3><p><img src="https://raw.githubusercontent.com/yichenchan/blogimg/master/img/dl2.1.png" alt=""></p>
<ul>
<li>目标：输入图片的特征向量 x，预测对应的输出是 1 还是 0 </li>
</ul>
<h3 id="图片特征值的提取"><a href="#图片特征值的提取" class="headerlink" title="图片特征值的提取"></a>图片特征值的提取</h3><p><img src="https://raw.githubusercontent.com/yichenchan/blogimg/master/img/dl2.2.png" alt=""><br></div><a class="more" href="/2018/08/07/吴恩达机器学习笔记c1w2/#more">阅读更多</a><hr></div><nav id="pagination"><div class="pagination"><a class="extend prev" rel="prev" href="/page/2/"><i class="fa fa-chevron-left"></i></a><a class="page-number" href="/">1</a><a class="page-number" href="/page/2/">2</a><span class="page-number current">3</span><a class="page-number" href="/page/4/">4</a><a class="extend next" rel="next" href="/page/4/"><i class="fa fa-chevron-right"></i></a></div></nav></div></div><footer><div class="layout" id="footer"><div class="copyright">&copy;2018 By 陈艺琛</div><div class="framework-info"><span>驱动 - </span><a href="http://hexo.io"><span>Hexo</span></a><span class="footer-separator">|</span><span>主题 - </span><a href="https://github.com/Molunerfinn/hexo-theme-melody"><span>Melody</span></a></div><div class="footer_custom_text">这里是我的一亩自耕田，记录自己的学习过程，生活随想和读书笔记，感谢您的参观！</div><div class="busuanzi"><script async src="//dn-lbstatics.qbox.me/busuanzi/2.3/busuanzi.pure.mini.js"></script><span id="busuanzi_container_site_uv"><i class="fa fa-user"></i><span id="busuanzi_value_site_uv"></span><span></span></span><span class="footer-separator">|</span><span id="busuanzi_container_site_pv"><i class="fa fa-eye"></i><span id="busuanzi_value_site_pv"></span><span></span></span></div></div></footer><i class="fa fa-arrow-up" id="go-up" aria-hidden="true"></i><script src="/js/third-party/anime.min.js"></script><script src="/js/third-party/jquery.min.js"></script><script src="/js/third-party/jquery.fancybox.min.js"></script><script src="/js/third-party/velocity.min.js"></script><script src="/js/third-party/velocity.ui.min.js"></script><script src="/js/utils.js?version=1.5.6"></script><script src="/js/fancybox.js?version=1.5.6"></script><script src="/js/sidebar.js?version=1.5.6"></script><script src="/js/copy.js?version=1.5.6"></script><script src="/js/fireworks.js?version=1.5.6"></script><script src="/js/transition.js?version=1.5.6"></script><script src="/js/scroll.js?version=1.5.6"></script><script src="/js/head.js?version=1.5.6"></script><script type="text/x-mathjax-config">MathJax.Hub.Config({
  tex2jax: {
    inlineMath: [ ['$','$'], ["\\(","\\)"]  ],
    processEscapes: true,
    skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
  },
  CommonHTML: {
    linebreaks: { automatic: true, width: "90% container" }
  },
  "HTML-CSS": { 
    linebreaks: { automatic: true, width: "90% container" }
  },
  "SVG": { 
    linebreaks: { automatic: true, width: "90% container" }
  }
});
</script><script type="text/x-mathjax-config">MathJax.Hub.Queue(function() {
  var all = MathJax.Hub.getAllJax(), i;
  for (i=0; i < all.length; i += 1) {
    all[i].SourceElement().parentNode.className += ' has-jax';
  }
});
</script><script src="https://cdn.bootcss.com/mathjax/2.7.2/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script><script src="/js/search/local-search.js"></script><div class="search-dialog" id="local-search"><div class="search-dialog__title" id="local-search-title">本地搜索</div><div id="local-input-panel"><div id="local-search-input"><div class="local-search-box"><input class="local-search-box--input" placeholder="搜索文章"></div></div></div><hr><div id="local-search-results"><div id="local-hits"></div><div id="local-stats"><div class="local-search-stats__hr" id="hr"><span>由</span> <a href="https://github.com/wzpan/hexo-generator-search" style="color:#49B1F5;">hexo-generator-search</a>
 <span>提供支持</span></div></div></div><span class="search-close-button"><i class="fa fa-times"></i></span></div><div class="search-mask"></div></body></html>